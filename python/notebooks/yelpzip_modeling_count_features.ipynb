{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "145108f6",
   "metadata": {},
   "source": [
    "#### Notebook Summary\n",
    "This notebook contains exploration of the various engineered features to understand whether these behavioral summary features have relationships with our target variable. This was part of our initial feature engineering and exploration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "886e90e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ecdd380",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"user_id\", \"product_id\", \"date\", \"full_review\", \"rating\", \"label\", \"word_list\",\n",
    "           \"lemmatized_word_list\", \"num_words\", \"num_verbs\", \"avg_word_len\", \"emotiveness_ratio\",\n",
    "           \"num_positive_words\", \"num_negative_words\", \"sentiment\"]\n",
    "preprocessed_data = pd.read_csv(\"../../data/preprocessing and features for modeling/review_features_02.txt\",\n",
    "                                delimiter=\"\\t\",\n",
    "                                names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8b8131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add count of previous reviews before the current onw\n",
    "preprocessed_data['previous_review_count'] = preprocessed_data.sort_values(['user_id', 'date']).groupby(['user_id']).cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed375cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add total amount of reviews and avg sentiment by this reviewer\n",
    "user_id_counts = preprocessed_data[['user_id', 'sentiment']].groupby('user_id').agg({'sentiment': ['mean', 'count']})\n",
    "user_id_counts.columns = ['avg_user_sentiment', 'total_user_reviews']\n",
    "preprocessed_data = preprocessed_data.merge(user_id_counts, on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ebcf695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add total amount of reviews and avg sentiment for this business\n",
    "product_id_counts = preprocessed_data[['product_id', 'sentiment']].groupby('product_id').agg({'sentiment': ['mean', 'count']})\n",
    "product_id_counts.columns = ['avg_business_sentiment', 'total_business_reviews']\n",
    "preprocessed_data = preprocessed_data.merge(product_id_counts, on='product_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52b6fba7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>date</th>\n",
       "      <th>full_review</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>word_list</th>\n",
       "      <th>lemmatized_word_list</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_verbs</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>emotiveness_ratio</th>\n",
       "      <th>num_positive_words</th>\n",
       "      <th>num_negative_words</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>previous_review_count</th>\n",
       "      <th>avg_user_sentiment</th>\n",
       "      <th>total_user_reviews</th>\n",
       "      <th>avg_business_sentiment</th>\n",
       "      <th>total_business_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5044</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-11-16</td>\n",
       "      <td>Drinks were bad, the hot chocolate was watered...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>['drinks', 'bad', 'hot', 'chocolate', 'watered...</td>\n",
       "      <td>['drink', 'bad', 'hot', 'chocolate', 'water', ...</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>4.882353</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.235294</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.235294</td>\n",
       "      <td>1</td>\n",
       "      <td>0.123241</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5045</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-09-08</td>\n",
       "      <td>This was the worst experience I've ever had a ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>['worst', 'experience', 'ive', 'ever', 'casual...</td>\n",
       "      <td>['bad', 'experience', 'ive', 'ever', 'casual',...</td>\n",
       "      <td>118</td>\n",
       "      <td>21</td>\n",
       "      <td>5.533898</td>\n",
       "      <td>0.430380</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.067797</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.067797</td>\n",
       "      <td>1</td>\n",
       "      <td>0.123241</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5046</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-10-06</td>\n",
       "      <td>This is located on the site of the old Spruce ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>['located', 'site', 'old', 'spruce', 'st', 'vi...</td>\n",
       "      <td>['locate', 'site', 'old', 'spruce', 'st', 'vid...</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>5.125000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>4</td>\n",
       "      <td>0.123241</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5047</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-11-30</td>\n",
       "      <td>I enjoyed coffee and breakfast twice at Toast ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>['enjoyed', 'coffee', 'breakfast', 'twice', 't...</td>\n",
       "      <td>['enjoy', 'coffee', 'breakfast', 'twice', 'toa...</td>\n",
       "      <td>129</td>\n",
       "      <td>15</td>\n",
       "      <td>5.651163</td>\n",
       "      <td>0.476744</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.124031</td>\n",
       "      <td>0</td>\n",
       "      <td>0.124031</td>\n",
       "      <td>1</td>\n",
       "      <td>0.123241</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5048</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-08-28</td>\n",
       "      <td>I love Toast! The food choices are fantastic -...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>['love', 'toast', 'food', 'choices', 'fantasti...</td>\n",
       "      <td>['love', 'toast', 'food', 'choice', 'fantastic...</td>\n",
       "      <td>79</td>\n",
       "      <td>11</td>\n",
       "      <td>5.354430</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.151899</td>\n",
       "      <td>0</td>\n",
       "      <td>0.151899</td>\n",
       "      <td>1</td>\n",
       "      <td>0.123241</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608593</th>\n",
       "      <td>259494</td>\n",
       "      <td>4877</td>\n",
       "      <td>2014-12-10</td>\n",
       "      <td>This is a new restaurant in Newark internation...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>['new', 'restaurant', 'newark', 'international...</td>\n",
       "      <td>['new', 'restaurant', 'newark', 'international...</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>4.976190</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608594</th>\n",
       "      <td>260401</td>\n",
       "      <td>4176</td>\n",
       "      <td>2011-06-07</td>\n",
       "      <td>If you appreciate a good sub roll, Slack's has...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>['appreciate', 'good', 'sub', 'roll', 'slacks'...</td>\n",
       "      <td>['appreciate', 'good', 'sub', 'roll', 'slack',...</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>4.937500</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.277244</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608595</th>\n",
       "      <td>260402</td>\n",
       "      <td>4176</td>\n",
       "      <td>2008-07-14</td>\n",
       "      <td>Best Philly Hoagies and Cheesesteaks on this s...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>['best', 'philly', 'hoagies', 'cheesesteaks', ...</td>\n",
       "      <td>['best', 'philly', 'hoagy', 'cheesesteaks', 's...</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>5.384615</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>0</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>1</td>\n",
       "      <td>0.277244</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608596</th>\n",
       "      <td>265185</td>\n",
       "      <td>2984</td>\n",
       "      <td>2014-12-18</td>\n",
       "      <td>The food here is amazing!  Authentic Haitian  ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>['food', 'amazing', 'authentic', 'haitian', 'c...</td>\n",
       "      <td>['food', 'amaze', 'authentic', 'haitian', 'cui...</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>6.233333</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.150758</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608597</th>\n",
       "      <td>265186</td>\n",
       "      <td>2984</td>\n",
       "      <td>2014-07-24</td>\n",
       "      <td>First of all I just had the Absolute Best chic...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>['first', 'absolute', 'best', 'chicken', 'patt...</td>\n",
       "      <td>['first', 'absolute', 'best', 'chicken', 'patt...</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>5.659091</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>0</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>1</td>\n",
       "      <td>0.150758</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608598 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  product_id        date  \\\n",
       "0          5044           0  2014-11-16   \n",
       "1          5045           0  2014-09-08   \n",
       "2          5046           0  2013-10-06   \n",
       "3          5047           0  2014-11-30   \n",
       "4          5048           0  2014-08-28   \n",
       "...         ...         ...         ...   \n",
       "608593   259494        4877  2014-12-10   \n",
       "608594   260401        4176  2011-06-07   \n",
       "608595   260402        4176  2008-07-14   \n",
       "608596   265185        2984  2014-12-18   \n",
       "608597   265186        2984  2014-07-24   \n",
       "\n",
       "                                              full_review  rating  label  \\\n",
       "0       Drinks were bad, the hot chocolate was watered...     1.0     -1   \n",
       "1       This was the worst experience I've ever had a ...     1.0     -1   \n",
       "2       This is located on the site of the old Spruce ...     3.0     -1   \n",
       "3       I enjoyed coffee and breakfast twice at Toast ...     5.0     -1   \n",
       "4       I love Toast! The food choices are fantastic -...     5.0     -1   \n",
       "...                                                   ...     ...    ...   \n",
       "608593  This is a new restaurant in Newark internation...     1.0      1   \n",
       "608594  If you appreciate a good sub roll, Slack's has...     5.0      1   \n",
       "608595  Best Philly Hoagies and Cheesesteaks on this s...     5.0      1   \n",
       "608596  The food here is amazing!  Authentic Haitian  ...     5.0      1   \n",
       "608597  First of all I just had the Absolute Best chic...     5.0      1   \n",
       "\n",
       "                                                word_list  \\\n",
       "0       ['drinks', 'bad', 'hot', 'chocolate', 'watered...   \n",
       "1       ['worst', 'experience', 'ive', 'ever', 'casual...   \n",
       "2       ['located', 'site', 'old', 'spruce', 'st', 'vi...   \n",
       "3       ['enjoyed', 'coffee', 'breakfast', 'twice', 't...   \n",
       "4       ['love', 'toast', 'food', 'choices', 'fantasti...   \n",
       "...                                                   ...   \n",
       "608593  ['new', 'restaurant', 'newark', 'international...   \n",
       "608594  ['appreciate', 'good', 'sub', 'roll', 'slacks'...   \n",
       "608595  ['best', 'philly', 'hoagies', 'cheesesteaks', ...   \n",
       "608596  ['food', 'amazing', 'authentic', 'haitian', 'c...   \n",
       "608597  ['first', 'absolute', 'best', 'chicken', 'patt...   \n",
       "\n",
       "                                     lemmatized_word_list  num_words  \\\n",
       "0       ['drink', 'bad', 'hot', 'chocolate', 'water', ...         17   \n",
       "1       ['bad', 'experience', 'ive', 'ever', 'casual',...        118   \n",
       "2       ['locate', 'site', 'old', 'spruce', 'st', 'vid...         24   \n",
       "3       ['enjoy', 'coffee', 'breakfast', 'twice', 'toa...        129   \n",
       "4       ['love', 'toast', 'food', 'choice', 'fantastic...         79   \n",
       "...                                                   ...        ...   \n",
       "608593  ['new', 'restaurant', 'newark', 'international...         42   \n",
       "608594  ['appreciate', 'good', 'sub', 'roll', 'slack',...         16   \n",
       "608595  ['best', 'philly', 'hoagy', 'cheesesteaks', 's...         39   \n",
       "608596  ['food', 'amaze', 'authentic', 'haitian', 'cui...         30   \n",
       "608597  ['first', 'absolute', 'best', 'chicken', 'patt...         44   \n",
       "\n",
       "        num_verbs  avg_word_len  emotiveness_ratio  num_positive_words  \\\n",
       "0               2      4.882353           0.416667                   1   \n",
       "1              21      5.533898           0.430380                   4   \n",
       "2               3      5.125000           0.500000                   4   \n",
       "3              15      5.651163           0.476744                  20   \n",
       "4              11      5.354430           0.500000                  12   \n",
       "...           ...           ...                ...                 ...   \n",
       "608593          8      4.976190           0.428571                   7   \n",
       "608594          2      4.937500           0.454545                   7   \n",
       "608595          2      5.384615           0.583333                   7   \n",
       "608596          3      6.233333           0.764706                   7   \n",
       "608597          2      5.659091           0.466667                   5   \n",
       "\n",
       "        num_negative_words  sentiment  previous_review_count  \\\n",
       "0                        5  -0.235294                      0   \n",
       "1                       12  -0.067797                      0   \n",
       "2                        1   0.125000                      2   \n",
       "3                        4   0.124031                      0   \n",
       "4                        0   0.151899                      0   \n",
       "...                    ...        ...                    ...   \n",
       "608593                   1   0.142857                      0   \n",
       "608594                   1   0.375000                      0   \n",
       "608595                   0   0.179487                      0   \n",
       "608596                   0   0.233333                      0   \n",
       "608597                   2   0.068182                      0   \n",
       "\n",
       "        avg_user_sentiment  total_user_reviews  avg_business_sentiment  \\\n",
       "0                -0.235294                   1                0.123241   \n",
       "1                -0.067797                   1                0.123241   \n",
       "2                 0.062500                   4                0.123241   \n",
       "3                 0.124031                   1                0.123241   \n",
       "4                 0.151899                   1                0.123241   \n",
       "...                    ...                 ...                     ...   \n",
       "608593            0.142857                   1                0.142857   \n",
       "608594            0.375000                   1                0.277244   \n",
       "608595            0.179487                   1                0.277244   \n",
       "608596            0.233333                   1                0.150758   \n",
       "608597            0.068182                   1                0.150758   \n",
       "\n",
       "        total_business_reviews  \n",
       "0                           88  \n",
       "1                           88  \n",
       "2                           88  \n",
       "3                           88  \n",
       "4                           88  \n",
       "...                        ...  \n",
       "608593                       1  \n",
       "608594                       2  \n",
       "608595                       2  \n",
       "608596                       2  \n",
       "608597                       2  \n",
       "\n",
       "[608598 rows x 20 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d836d787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ea355c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_features = ['num_words', 'num_verbs', 'avg_word_len', 'emotiveness_ratio',\n",
    "                 'num_positive_words', 'num_negative_words', 'sentiment', 'rating']\n",
    "new_features = ['previous_review_count', 'avg_user_sentiment', 'total_user_reviews',\n",
    "                'avg_business_sentiment', 'total_business_reviews']\n",
    "label_col = 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cb09800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4min 27s\n",
      "Wall time: 4min 29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Data_Science_Studies\\GTech\\.venv\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;upsampler&#x27;, SMOTE(k_neighbors=3, random_state=24)),\n",
       "                (&#x27;svc&#x27;, LinearSVC())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;upsampler&#x27;, SMOTE(k_neighbors=3, random_state=24)),\n",
       "                (&#x27;svc&#x27;, LinearSVC())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE(k_neighbors=3, random_state=24)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('upsampler', SMOTE(k_neighbors=3, random_state=24)),\n",
       "                ('svc', LinearSVC())])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Baseline model without any direct representation of words or word embeddings\n",
    "\n",
    "# Using a linear kernel for now as I have seen pretty good results for linear SVM with text classification\n",
    "# Using LinearSVC for better performance on large data sets\n",
    "baseline_svm = LinearSVC()\n",
    "\n",
    "# Best practice scale data when using geometric based models like SVM where magnitude is important\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Best practice to split the data before scaling, so that the scaler is fit on only the training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(preprocessed_data[orig_features + new_features],\n",
    "                                                    preprocessed_data[label_col].values,\n",
    "                                                    test_size=.3,\n",
    "                                                    random_state=24)\n",
    "\n",
    "# Minority class is significantly less than majority class, so we should use SMOTE to upsample the data\n",
    "resampler = SMOTE(random_state=24, k_neighbors=3)\n",
    "\n",
    "# Using imblearn pipeline to manage the scaling and resampling logic in a simple way\n",
    "svm_pipe = Pipeline([('scaler', scaler),\n",
    "                     ('upsampler', resampler),\n",
    "                     ('svc', baseline_svm)])\n",
    "\n",
    "svm_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b412bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.22      0.87      0.35     24121\n",
      "           1       0.96      0.54      0.69    158459\n",
      "\n",
      "    accuracy                           0.58    182580\n",
      "   macro avg       0.59      0.70      0.52    182580\n",
      "weighted avg       0.87      0.58      0.64    182580\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[20995,  3126],\n",
       "       [73677, 84782]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All columns\n",
    "preds = svm_pipe.predict(X_test)\n",
    "print(metrics.classification_report(y_test, preds))\n",
    "metrics.confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48c0d3e8",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Data_Science_Studies\\GTech\\.venv\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "E:\\Data_Science_Studies\\GTech\\.venv\\lib\\site-packages\\sklearn\\base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names unseen at fit time:\n",
      "- avg_business_sentiment\n",
      "- avg_user_sentiment\n",
      "- previous_review_count\n",
      "- total_business_reviews\n",
      "- total_user_reviews\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 13 features, but StandardScaler is expecting 8 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m svm_pipe\u001b[38;5;241m.\u001b[39mfit(X_train[orig_features], y_train)\n\u001b[1;32m----> 2\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43msvm_pipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(metrics\u001b[38;5;241m.\u001b[39mclassification_report(y_test, preds))\n\u001b[0;32m      4\u001b[0m metrics\u001b[38;5;241m.\u001b[39mconfusion_matrix(y_test, preds)\n",
      "File \u001b[1;32mE:\\Data_Science_Studies\\GTech\\.venv\\lib\\site-packages\\sklearn\\pipeline.py:457\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    455\u001b[0m Xt \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 457\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params)\n",
      "File \u001b[1;32mE:\\Data_Science_Studies\\GTech\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:975\u001b[0m, in \u001b[0;36mStandardScaler.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m    972\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    974\u001b[0m copy \u001b[38;5;241m=\u001b[39m copy \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy\n\u001b[1;32m--> 975\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    978\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    982\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sparse\u001b[38;5;241m.\u001b[39missparse(X):\n\u001b[0;32m    985\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_mean:\n",
      "File \u001b[1;32mE:\\Data_Science_Studies\\GTech\\.venv\\lib\\site-packages\\sklearn\\base.py:600\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    597\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 600\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mE:\\Data_Science_Studies\\GTech\\.venv\\lib\\site-packages\\sklearn\\base.py:400\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    401\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    402\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    403\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 13 features, but StandardScaler is expecting 8 features as input."
     ]
    }
   ],
   "source": [
    "# Just old columns\n",
    "svm_pipe.fit(X_train[orig_features], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c8f606b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.18      0.67      0.28     24121\n",
      "           1       0.91      0.53      0.67    158459\n",
      "\n",
      "    accuracy                           0.55    182580\n",
      "   macro avg       0.54      0.60      0.48    182580\n",
      "weighted avg       0.82      0.55      0.62    182580\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[16051,  8070],\n",
       "       [74401, 84058]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = svm_pipe.predict(X_test[orig_features])\n",
    "print(metrics.classification_report(y_test, preds))\n",
    "metrics.confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d15db54",
   "metadata": {},
   "source": [
    "The new columns added (avg_user_sentiment, avg_business_sentiment, total_user_reviews, total_business_reviews, previous_review_count) definitely appear to have some valuable information that helps in identifying the fake reviews. By including these features we improve both the precision and the recall. We still have an issue where we are over-identifying the true reviews as fake, but we are trending in the right direction. Let's try combining these with the TF-IDF representation and see if we can improve over the previous model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5970cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67fe3215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426018, 14)\n",
      "(182580, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;summary&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;num_words&#x27;, &#x27;num_verbs&#x27;,\n",
       "                                                   &#x27;avg_word_len&#x27;,\n",
       "                                                   &#x27;emotiveness_ratio&#x27;,\n",
       "                                                   &#x27;num_positive_words&#x27;,\n",
       "                                                   &#x27;num_negative_words&#x27;,\n",
       "                                                   &#x27;sentiment&#x27;, &#x27;rating&#x27;,\n",
       "                                                   &#x27;previous_review_count&#x27;,\n",
       "                                                   &#x27;avg_user_sentiment&#x27;,\n",
       "                                                   &#x27;total_user_reviews&#x27;,\n",
       "                                                   &#x27;avg_business_sentiment&#x27;,\n",
       "                                                   &#x27;total_business_reviews&#x27;]),\n",
       "                                                 (&#x27;tfidf&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
       "                                                                   TfidfVectorizer())]),\n",
       "                                                  &#x27;lemmatized_word_list&#x27;)])),\n",
       "                (&#x27;upsampler&#x27;, SMOTE(k_neighbors=3, random_state=24)),\n",
       "                (&#x27;svc&#x27;, LinearSVC())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;summary&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;num_words&#x27;, &#x27;num_verbs&#x27;,\n",
       "                                                   &#x27;avg_word_len&#x27;,\n",
       "                                                   &#x27;emotiveness_ratio&#x27;,\n",
       "                                                   &#x27;num_positive_words&#x27;,\n",
       "                                                   &#x27;num_negative_words&#x27;,\n",
       "                                                   &#x27;sentiment&#x27;, &#x27;rating&#x27;,\n",
       "                                                   &#x27;previous_review_count&#x27;,\n",
       "                                                   &#x27;avg_user_sentiment&#x27;,\n",
       "                                                   &#x27;total_user_reviews&#x27;,\n",
       "                                                   &#x27;avg_business_sentiment&#x27;,\n",
       "                                                   &#x27;total_business_reviews&#x27;]),\n",
       "                                                 (&#x27;tfidf&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
       "                                                                   TfidfVectorizer())]),\n",
       "                                                  &#x27;lemmatized_word_list&#x27;)])),\n",
       "                (&#x27;upsampler&#x27;, SMOTE(k_neighbors=3, random_state=24)),\n",
       "                (&#x27;svc&#x27;, LinearSVC())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessing: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;summary&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;num_words&#x27;, &#x27;num_verbs&#x27;, &#x27;avg_word_len&#x27;,\n",
       "                                  &#x27;emotiveness_ratio&#x27;, &#x27;num_positive_words&#x27;,\n",
       "                                  &#x27;num_negative_words&#x27;, &#x27;sentiment&#x27;, &#x27;rating&#x27;,\n",
       "                                  &#x27;previous_review_count&#x27;, &#x27;avg_user_sentiment&#x27;,\n",
       "                                  &#x27;total_user_reviews&#x27;,\n",
       "                                  &#x27;avg_business_sentiment&#x27;,\n",
       "                                  &#x27;total_business_reviews&#x27;]),\n",
       "                                (&#x27;tfidf&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
       "                                                  TfidfVectorizer())]),\n",
       "                                 &#x27;lemmatized_word_list&#x27;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">summary</label><div class=\"sk-toggleable__content\"><pre>[&#x27;num_words&#x27;, &#x27;num_verbs&#x27;, &#x27;avg_word_len&#x27;, &#x27;emotiveness_ratio&#x27;, &#x27;num_positive_words&#x27;, &#x27;num_negative_words&#x27;, &#x27;sentiment&#x27;, &#x27;rating&#x27;, &#x27;previous_review_count&#x27;, &#x27;avg_user_sentiment&#x27;, &#x27;total_user_reviews&#x27;, &#x27;avg_business_sentiment&#x27;, &#x27;total_business_reviews&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">tfidf</label><div class=\"sk-toggleable__content\"><pre>lemmatized_word_list</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE(k_neighbors=3, random_state=24)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 ColumnTransformer(transformers=[('summary',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['num_words', 'num_verbs',\n",
       "                                                   'avg_word_len',\n",
       "                                                   'emotiveness_ratio',\n",
       "                                                   'num_positive_words',\n",
       "                                                   'num_negative_words',\n",
       "                                                   'sentiment', 'rating',\n",
       "                                                   'previous_review_count',\n",
       "                                                   'avg_user_sentiment',\n",
       "                                                   'total_user_reviews',\n",
       "                                                   'avg_business_sentiment',\n",
       "                                                   'total_business_reviews']),\n",
       "                                                 ('tfidf',\n",
       "                                                  Pipeline(steps=[('vectorizer',\n",
       "                                                                   TfidfVectorizer())]),\n",
       "                                                  'lemmatized_word_list')])),\n",
       "                ('upsampler', SMOTE(k_neighbors=3, random_state=24)),\n",
       "                ('svc', LinearSVC())])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "tfidf_combined_svm = LinearSVC()\n",
    "X_train, X_test, y_train, y_test = train_test_split(preprocessed_data[orig_features + new_features + ['lemmatized_word_list']],\n",
    "                                                    preprocessed_data[label_col].values,\n",
    "                                                    test_size=.3,\n",
    "                                                    random_state=24)\n",
    "\n",
    "summary_pipeline = Pipeline([('scaler', StandardScaler())])\n",
    "tfidf_pipeline = Pipeline([('vectorizer', TfidfVectorizer(analyzer='word', ngram_range=(1,1)))])\n",
    "column_processor = ColumnTransformer([('summary', summary_pipeline, orig_features + new_features),\n",
    "                                      ('tfidf', tfidf_pipeline, 'lemmatized_word_list')])\n",
    "\n",
    "\n",
    "tfidf_combined_svm_pipe = Pipeline([('preprocessing', column_processor),\n",
    "                                    ('upsampler', resampler),\n",
    "                                    ('svc', tfidf_combined_svm)])\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "tfidf_combined_svm_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6a90518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 11min 48s\n",
      "Wall time: 11min 56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Data_Science_Studies\\GTech\\.venv\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;summary&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;num_words&#x27;, &#x27;num_verbs&#x27;,\n",
       "                                                   &#x27;avg_word_len&#x27;,\n",
       "                                                   &#x27;emotiveness_ratio&#x27;,\n",
       "                                                   &#x27;num_positive_words&#x27;,\n",
       "                                                   &#x27;num_negative_words&#x27;,\n",
       "                                                   &#x27;sentiment&#x27;, &#x27;rating&#x27;,\n",
       "                                                   &#x27;previous_review_count&#x27;,\n",
       "                                                   &#x27;avg_user_sentiment&#x27;,\n",
       "                                                   &#x27;total_user_reviews&#x27;,\n",
       "                                                   &#x27;avg_business_sentiment&#x27;,\n",
       "                                                   &#x27;total_business_reviews&#x27;]),\n",
       "                                                 (&#x27;tfidf&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
       "                                                                   TfidfVectorizer())]),\n",
       "                                                  &#x27;lemmatized_word_list&#x27;)])),\n",
       "                (&#x27;upsampler&#x27;, SMOTE(k_neighbors=3, random_state=24)),\n",
       "                (&#x27;svc&#x27;, LinearSVC())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;summary&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;num_words&#x27;, &#x27;num_verbs&#x27;,\n",
       "                                                   &#x27;avg_word_len&#x27;,\n",
       "                                                   &#x27;emotiveness_ratio&#x27;,\n",
       "                                                   &#x27;num_positive_words&#x27;,\n",
       "                                                   &#x27;num_negative_words&#x27;,\n",
       "                                                   &#x27;sentiment&#x27;, &#x27;rating&#x27;,\n",
       "                                                   &#x27;previous_review_count&#x27;,\n",
       "                                                   &#x27;avg_user_sentiment&#x27;,\n",
       "                                                   &#x27;total_user_reviews&#x27;,\n",
       "                                                   &#x27;avg_business_sentiment&#x27;,\n",
       "                                                   &#x27;total_business_reviews&#x27;]),\n",
       "                                                 (&#x27;tfidf&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
       "                                                                   TfidfVectorizer())]),\n",
       "                                                  &#x27;lemmatized_word_list&#x27;)])),\n",
       "                (&#x27;upsampler&#x27;, SMOTE(k_neighbors=3, random_state=24)),\n",
       "                (&#x27;svc&#x27;, LinearSVC())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessing: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;summary&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;num_words&#x27;, &#x27;num_verbs&#x27;, &#x27;avg_word_len&#x27;,\n",
       "                                  &#x27;emotiveness_ratio&#x27;, &#x27;num_positive_words&#x27;,\n",
       "                                  &#x27;num_negative_words&#x27;, &#x27;sentiment&#x27;, &#x27;rating&#x27;,\n",
       "                                  &#x27;previous_review_count&#x27;, &#x27;avg_user_sentiment&#x27;,\n",
       "                                  &#x27;total_user_reviews&#x27;,\n",
       "                                  &#x27;avg_business_sentiment&#x27;,\n",
       "                                  &#x27;total_business_reviews&#x27;]),\n",
       "                                (&#x27;tfidf&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
       "                                                  TfidfVectorizer())]),\n",
       "                                 &#x27;lemmatized_word_list&#x27;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">summary</label><div class=\"sk-toggleable__content\"><pre>[&#x27;num_words&#x27;, &#x27;num_verbs&#x27;, &#x27;avg_word_len&#x27;, &#x27;emotiveness_ratio&#x27;, &#x27;num_positive_words&#x27;, &#x27;num_negative_words&#x27;, &#x27;sentiment&#x27;, &#x27;rating&#x27;, &#x27;previous_review_count&#x27;, &#x27;avg_user_sentiment&#x27;, &#x27;total_user_reviews&#x27;, &#x27;avg_business_sentiment&#x27;, &#x27;total_business_reviews&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">tfidf</label><div class=\"sk-toggleable__content\"><pre>lemmatized_word_list</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE(k_neighbors=3, random_state=24)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 ColumnTransformer(transformers=[('summary',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['num_words', 'num_verbs',\n",
       "                                                   'avg_word_len',\n",
       "                                                   'emotiveness_ratio',\n",
       "                                                   'num_positive_words',\n",
       "                                                   'num_negative_words',\n",
       "                                                   'sentiment', 'rating',\n",
       "                                                   'previous_review_count',\n",
       "                                                   'avg_user_sentiment',\n",
       "                                                   'total_user_reviews',\n",
       "                                                   'avg_business_sentiment',\n",
       "                                                   'total_business_reviews']),\n",
       "                                                 ('tfidf',\n",
       "                                                  Pipeline(steps=[('vectorizer',\n",
       "                                                                   TfidfVectorizer())]),\n",
       "                                                  'lemmatized_word_list')])),\n",
       "                ('upsampler', SMOTE(k_neighbors=3, random_state=24)),\n",
       "                ('svc', LinearSVC())])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tfidf_combined_svm_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e84345e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.27      0.60      0.38     24121\n",
      "           1       0.93      0.76      0.83    158459\n",
      "\n",
      "    accuracy                           0.74    182580\n",
      "   macro avg       0.60      0.68      0.60    182580\n",
      "weighted avg       0.84      0.74      0.77    182580\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 14545,   9576],\n",
       "       [ 38514, 119945]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_combined_preds = tfidf_combined_svm_pipe.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, tfidf_combined_preds))\n",
    "metrics.confusion_matrix(y_test, tfidf_combined_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe171539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426018, 14)\n",
      "(182580, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Data_Science_Studies\\GTech\\.venv\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.27      0.64      0.38     24121\n",
      "           1       0.93      0.74      0.82    158459\n",
      "\n",
      "    accuracy                           0.72    182580\n",
      "   macro avg       0.60      0.69      0.60    182580\n",
      "weighted avg       0.84      0.72      0.76    182580\n",
      "\n",
      "CPU times: total: 4min 37s\n",
      "Wall time: 4min 40s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 15550,   8571],\n",
       "       [ 41963, 116496]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Trying to use an alternative to SMOTE\n",
    "tfidf_combined_svm = LinearSVC(class_weight='balanced')\n",
    "X_train, X_test, y_train, y_test = train_test_split(preprocessed_data[orig_features + new_features + ['lemmatized_word_list']],\n",
    "                                                    preprocessed_data[label_col].values,\n",
    "                                                    test_size=.3,\n",
    "                                                    random_state=24)\n",
    "\n",
    "summary_pipeline = Pipeline([('scaler', StandardScaler())])\n",
    "tfidf_pipeline = Pipeline([('vectorizer', TfidfVectorizer(analyzer='word', ngram_range=(1,1)))])\n",
    "column_processor = ColumnTransformer([('summary', summary_pipeline, orig_features + new_features),\n",
    "                                      ('tfidf', tfidf_pipeline, 'lemmatized_word_list')])\n",
    "\n",
    "\n",
    "tfidf_combined_svm_pipe = Pipeline([('preprocessing', column_processor),\n",
    "                                    ('svc', tfidf_combined_svm)])\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "tfidf_combined_svm_pipe.fit(X_train, y_train)\n",
    "\n",
    "tfidf_combined_preds = tfidf_combined_svm_pipe.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, tfidf_combined_preds))\n",
    "metrics.confusion_matrix(y_test, tfidf_combined_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab872213",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = ['.', ',', '!', '?', ':', ';']\n",
    "\n",
    "\n",
    "for p in punctuation:\n",
    "    preprocessed_data[f'{p}_count'] = preprocessed_data.full_review.str.count(f'\\\\{p}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46523045",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_features = ['._count', ',_count', '!_count', '?_count', ':_count', ';_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3a588893",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426018, 20)\n",
      "(182580, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Data_Science_Studies\\GTech\\.venv\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.27      0.65      0.38     24121\n",
      "           1       0.93      0.73      0.82    158459\n",
      "\n",
      "    accuracy                           0.72    182580\n",
      "   macro avg       0.60      0.69      0.60    182580\n",
      "weighted avg       0.84      0.72      0.76    182580\n",
      "\n",
      "CPU times: total: 4min 36s\n",
      "Wall time: 4min 40s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 15579,   8542],\n",
       "       [ 42147, 116312]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Trying to use an alternative to SMOTE with punctuation features\n",
    "tfidf_combined_svm = LinearSVC(class_weight='balanced')\n",
    "X_train, X_test, y_train, y_test = train_test_split(preprocessed_data[orig_features + new_features + punctuation_features + ['lemmatized_word_list']],\n",
    "                                                    preprocessed_data[label_col].values,\n",
    "                                                    test_size=.3,\n",
    "                                                    random_state=24)\n",
    "\n",
    "summary_pipeline = Pipeline([('scaler', StandardScaler())])\n",
    "tfidf_pipeline = Pipeline([('vectorizer', TfidfVectorizer(analyzer='word', ngram_range=(1,1)))])\n",
    "column_processor = ColumnTransformer([('summary', summary_pipeline, orig_features + new_features),\n",
    "                                      ('tfidf', tfidf_pipeline, 'lemmatized_word_list')])\n",
    "\n",
    "\n",
    "tfidf_combined_svm_pipe = Pipeline([('preprocessing', column_processor),\n",
    "                                    ('svc', tfidf_combined_svm)])\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "tfidf_combined_svm_pipe.fit(X_train, y_train)\n",
    "\n",
    "tfidf_combined_preds = tfidf_combined_svm_pipe.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, tfidf_combined_preds))\n",
    "metrics.confusion_matrix(y_test, tfidf_combined_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f13691cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'product_id', 'date', 'full_review', 'rating', 'label',\n",
       "       'word_list', 'lemmatized_word_list', 'num_words', 'num_verbs',\n",
       "       'avg_word_len', 'emotiveness_ratio', 'num_positive_words',\n",
       "       'num_negative_words', 'sentiment', 'previous_review_count',\n",
       "       'avg_user_sentiment', 'total_user_reviews', 'avg_business_sentiment',\n",
       "       'total_business_reviews', '._count', ',_count', '!_count', '?_count',\n",
       "       ':_count', ';_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2de029b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>date</th>\n",
       "      <th>full_review</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>word_list</th>\n",
       "      <th>lemmatized_word_list</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_verbs</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_user_sentiment</th>\n",
       "      <th>total_user_reviews</th>\n",
       "      <th>avg_business_sentiment</th>\n",
       "      <th>total_business_reviews</th>\n",
       "      <th>._count</th>\n",
       "      <th>,_count</th>\n",
       "      <th>!_count</th>\n",
       "      <th>?_count</th>\n",
       "      <th>:_count</th>\n",
       "      <th>;_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5044</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-11-16</td>\n",
       "      <td>Drinks were bad, the hot chocolate was watered...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>['drinks', 'bad', 'hot', 'chocolate', 'watered...</td>\n",
       "      <td>['drink', 'bad', 'hot', 'chocolate', 'water', ...</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.235294</td>\n",
       "      <td>1</td>\n",
       "      <td>0.123241</td>\n",
       "      <td>88</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5045</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-09-08</td>\n",
       "      <td>This was the worst experience I've ever had a ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>['worst', 'experience', 'ive', 'ever', 'casual...</td>\n",
       "      <td>['bad', 'experience', 'ive', 'ever', 'casual',...</td>\n",
       "      <td>118</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067797</td>\n",
       "      <td>1</td>\n",
       "      <td>0.123241</td>\n",
       "      <td>88</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5046</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-10-06</td>\n",
       "      <td>This is located on the site of the old Spruce ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>['located', 'site', 'old', 'spruce', 'st', 'vi...</td>\n",
       "      <td>['locate', 'site', 'old', 'spruce', 'st', 'vid...</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>4</td>\n",
       "      <td>0.123241</td>\n",
       "      <td>88</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5047</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-11-30</td>\n",
       "      <td>I enjoyed coffee and breakfast twice at Toast ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>['enjoyed', 'coffee', 'breakfast', 'twice', 't...</td>\n",
       "      <td>['enjoy', 'coffee', 'breakfast', 'twice', 'toa...</td>\n",
       "      <td>129</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124031</td>\n",
       "      <td>1</td>\n",
       "      <td>0.123241</td>\n",
       "      <td>88</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5048</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-08-28</td>\n",
       "      <td>I love Toast! The food choices are fantastic -...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>['love', 'toast', 'food', 'choices', 'fantasti...</td>\n",
       "      <td>['love', 'toast', 'food', 'choice', 'fantastic...</td>\n",
       "      <td>79</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151899</td>\n",
       "      <td>1</td>\n",
       "      <td>0.123241</td>\n",
       "      <td>88</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608593</th>\n",
       "      <td>259494</td>\n",
       "      <td>4877</td>\n",
       "      <td>2014-12-10</td>\n",
       "      <td>This is a new restaurant in Newark internation...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>['new', 'restaurant', 'newark', 'international...</td>\n",
       "      <td>['new', 'restaurant', 'newark', 'international...</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608594</th>\n",
       "      <td>260401</td>\n",
       "      <td>4176</td>\n",
       "      <td>2011-06-07</td>\n",
       "      <td>If you appreciate a good sub roll, Slack's has...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>['appreciate', 'good', 'sub', 'roll', 'slacks'...</td>\n",
       "      <td>['appreciate', 'good', 'sub', 'roll', 'slack',...</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.277244</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608595</th>\n",
       "      <td>260402</td>\n",
       "      <td>4176</td>\n",
       "      <td>2008-07-14</td>\n",
       "      <td>Best Philly Hoagies and Cheesesteaks on this s...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>['best', 'philly', 'hoagies', 'cheesesteaks', ...</td>\n",
       "      <td>['best', 'philly', 'hoagy', 'cheesesteaks', 's...</td>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>1</td>\n",
       "      <td>0.277244</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608596</th>\n",
       "      <td>265185</td>\n",
       "      <td>2984</td>\n",
       "      <td>2014-12-18</td>\n",
       "      <td>The food here is amazing!  Authentic Haitian  ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>['food', 'amazing', 'authentic', 'haitian', 'c...</td>\n",
       "      <td>['food', 'amaze', 'authentic', 'haitian', 'cui...</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.150758</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608597</th>\n",
       "      <td>265186</td>\n",
       "      <td>2984</td>\n",
       "      <td>2014-07-24</td>\n",
       "      <td>First of all I just had the Absolute Best chic...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>['first', 'absolute', 'best', 'chicken', 'patt...</td>\n",
       "      <td>['first', 'absolute', 'best', 'chicken', 'patt...</td>\n",
       "      <td>44</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068182</td>\n",
       "      <td>1</td>\n",
       "      <td>0.150758</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608598 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  product_id        date  \\\n",
       "0          5044           0  2014-11-16   \n",
       "1          5045           0  2014-09-08   \n",
       "2          5046           0  2013-10-06   \n",
       "3          5047           0  2014-11-30   \n",
       "4          5048           0  2014-08-28   \n",
       "...         ...         ...         ...   \n",
       "608593   259494        4877  2014-12-10   \n",
       "608594   260401        4176  2011-06-07   \n",
       "608595   260402        4176  2008-07-14   \n",
       "608596   265185        2984  2014-12-18   \n",
       "608597   265186        2984  2014-07-24   \n",
       "\n",
       "                                              full_review  rating  label  \\\n",
       "0       Drinks were bad, the hot chocolate was watered...     1.0     -1   \n",
       "1       This was the worst experience I've ever had a ...     1.0     -1   \n",
       "2       This is located on the site of the old Spruce ...     3.0     -1   \n",
       "3       I enjoyed coffee and breakfast twice at Toast ...     5.0     -1   \n",
       "4       I love Toast! The food choices are fantastic -...     5.0     -1   \n",
       "...                                                   ...     ...    ...   \n",
       "608593  This is a new restaurant in Newark internation...     1.0      1   \n",
       "608594  If you appreciate a good sub roll, Slack's has...     5.0      1   \n",
       "608595  Best Philly Hoagies and Cheesesteaks on this s...     5.0      1   \n",
       "608596  The food here is amazing!  Authentic Haitian  ...     5.0      1   \n",
       "608597  First of all I just had the Absolute Best chic...     5.0      1   \n",
       "\n",
       "                                                word_list  \\\n",
       "0       ['drinks', 'bad', 'hot', 'chocolate', 'watered...   \n",
       "1       ['worst', 'experience', 'ive', 'ever', 'casual...   \n",
       "2       ['located', 'site', 'old', 'spruce', 'st', 'vi...   \n",
       "3       ['enjoyed', 'coffee', 'breakfast', 'twice', 't...   \n",
       "4       ['love', 'toast', 'food', 'choices', 'fantasti...   \n",
       "...                                                   ...   \n",
       "608593  ['new', 'restaurant', 'newark', 'international...   \n",
       "608594  ['appreciate', 'good', 'sub', 'roll', 'slacks'...   \n",
       "608595  ['best', 'philly', 'hoagies', 'cheesesteaks', ...   \n",
       "608596  ['food', 'amazing', 'authentic', 'haitian', 'c...   \n",
       "608597  ['first', 'absolute', 'best', 'chicken', 'patt...   \n",
       "\n",
       "                                     lemmatized_word_list  num_words  \\\n",
       "0       ['drink', 'bad', 'hot', 'chocolate', 'water', ...         17   \n",
       "1       ['bad', 'experience', 'ive', 'ever', 'casual',...        118   \n",
       "2       ['locate', 'site', 'old', 'spruce', 'st', 'vid...         24   \n",
       "3       ['enjoy', 'coffee', 'breakfast', 'twice', 'toa...        129   \n",
       "4       ['love', 'toast', 'food', 'choice', 'fantastic...         79   \n",
       "...                                                   ...        ...   \n",
       "608593  ['new', 'restaurant', 'newark', 'international...         42   \n",
       "608594  ['appreciate', 'good', 'sub', 'roll', 'slack',...         16   \n",
       "608595  ['best', 'philly', 'hoagy', 'cheesesteaks', 's...         39   \n",
       "608596  ['food', 'amaze', 'authentic', 'haitian', 'cui...         30   \n",
       "608597  ['first', 'absolute', 'best', 'chicken', 'patt...         44   \n",
       "\n",
       "        num_verbs  ...  avg_user_sentiment  total_user_reviews  \\\n",
       "0               2  ...           -0.235294                   1   \n",
       "1              21  ...           -0.067797                   1   \n",
       "2               3  ...            0.062500                   4   \n",
       "3              15  ...            0.124031                   1   \n",
       "4              11  ...            0.151899                   1   \n",
       "...           ...  ...                 ...                 ...   \n",
       "608593          8  ...            0.142857                   1   \n",
       "608594          2  ...            0.375000                   1   \n",
       "608595          2  ...            0.179487                   1   \n",
       "608596          3  ...            0.233333                   1   \n",
       "608597          2  ...            0.068182                   1   \n",
       "\n",
       "        avg_business_sentiment  total_business_reviews  ._count  ,_count  \\\n",
       "0                     0.123241                      88        2        3   \n",
       "1                     0.123241                      88       15        9   \n",
       "2                     0.123241                      88        5        1   \n",
       "3                     0.123241                      88       15       16   \n",
       "4                     0.123241                      88        6        2   \n",
       "...                        ...                     ...      ...      ...   \n",
       "608593                0.142857                       1        8        0   \n",
       "608594                0.277244                       2        3        1   \n",
       "608595                0.277244                       2        8        3   \n",
       "608596                0.150758                       2        7        4   \n",
       "608597                0.150758                       2        5        2   \n",
       "\n",
       "        !_count  ?_count  :_count  ;_count  \n",
       "0             0        0        0        0  \n",
       "1             0        1        0        0  \n",
       "2             0        0        0        0  \n",
       "3             2        0        0        0  \n",
       "4             2        0        0        0  \n",
       "...         ...      ...      ...      ...  \n",
       "608593        3        0        0        1  \n",
       "608594        0        0        0        0  \n",
       "608595        2        0        0        0  \n",
       "608596        8        0        0        0  \n",
       "608597        1        0        0        0  \n",
       "\n",
       "[608598 rows x 26 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34be991",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gatech",
   "language": "python",
   "name": "gatech"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
