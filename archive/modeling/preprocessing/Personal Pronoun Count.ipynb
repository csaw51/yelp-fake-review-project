{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b51a761f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d85824a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  prod_id        date  \\\n",
      "0     5044        0  2014-11-16   \n",
      "1     5045        0  2014-09-08   \n",
      "2     5046        0  2013-10-06   \n",
      "3     5047        0  2014-11-30   \n",
      "4     5048        0  2014-08-28   \n",
      "\n",
      "                                              review  rating  label  \n",
      "0  Drinks were bad, the hot chocolate was watered...     1.0     -1  \n",
      "1  This was the worst experience I've ever had a ...     1.0     -1  \n",
      "2  This is located on the site of the old Spruce ...     3.0     -1  \n",
      "3  I enjoyed coffee and breakfast twice at Toast ...     5.0     -1  \n",
      "4  I love Toast! The food choices are fantastic -...     5.0     -1  \n",
      "length of data: 608598\n",
      "check the null data: False\n"
     ]
    }
   ],
   "source": [
    "file_review3=\"C:/Users/Lu/PycharmProjects/Group_Project/orig_review_with_labeling_608598rows.txt\"\n",
    "review3=pd.read_csv(file_review3,sep=\"\\t\",header=None)\n",
    "review3.columns=['user_id', 'prod_id', 'date', 'review', 'rating', 'label']\n",
    "print(review3.head())\n",
    "print(\"length of data:\",len(review3))\n",
    "print(\"check the null data:\",review3.isnull().values.any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90cde1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_pronoun=['i','you','u','he','she','it','we','they','me','him','her','us','them']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c17d983a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review\n",
      "0  Drinks were bad, the hot chocolate was watered...\n",
      "1  This was the worst experience I've ever had a ...\n",
      "2  This is located on the site of the old Spruce ...\n",
      "3  I enjoyed coffee and breakfast twice at Toast ...\n",
      "4  I love Toast! The food choices are fantastic -...\n"
     ]
    }
   ],
   "source": [
    "review=review3[['review']]\n",
    "print(review.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "091d78d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(608598, 2)\n"
     ]
    }
   ],
   "source": [
    "length=len(review)\n",
    "empty_col=np.empty([length,1])\n",
    "df=review.copy()\n",
    "df=np.append(df,empty_col,1)\n",
    "print(df.shape)\n",
    "for i in range(length):\n",
    "    # a.lower the text\n",
    "    text=df[i,0].lower()\n",
    "    text = text.replace(\"_\", \" \")\n",
    "    #text = text.replace(\"\\\\x\", \" \")   # deal with \\x..........\n",
    "    text = re.sub(br'(\\xc2)(.)', b'', text.encode('utf-8')).decode()\n",
    "    text = text.replace(\"can't\", \"can not\")\n",
    "    text = text.replace(\"won't\", \"will not\")\n",
    "    text = text.replace(\"'ve\",\" have\")\n",
    "    text = text.replace(\"'d\",\" had\")\n",
    "    text = text.replace(\"'m\", \" am\")\n",
    "    text = text.replace(\"'ll\", \" will\")\n",
    "    text = text.replace(\"'s\", \" is\")\n",
    "    text = text.replace(\"n't\", \" not\")\n",
    "    text = text.replace(\"'re\", \" are\")\n",
    "    text = text.replace(\"st.\", \"street\")\n",
    "    text = text.replace(\"bldg.\", \"building\") \n",
    "    text=re.sub(r\"[^\\w\\s]\", \" \", text) \n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "    word_tokens = word_tokenize(text)\n",
    "    df[i,1]=word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "078e4432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Drinks were bad, the hot chocolate was watered down and the latte had a burnt taste to it. The food was also poor quality, but the service was the worst part, their cashier was very rude.'\n",
      "  list(['drinks', 'were', 'bad', 'the', 'hot', 'chocolate', 'was', 'watered', 'down', 'and', 'the', 'latte', 'had', 'a', 'burnt', 'taste', 'to', 'it', 'the', 'food', 'was', 'also', 'poor', 'quality', 'but', 'the', 'service', 'was', 'the', 'worst', 'part', 'their', 'cashier', 'was', 'very', 'rude'])]]\n"
     ]
    }
   ],
   "source": [
    "print(df[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c365c8c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(608598, 3)\n"
     ]
    }
   ],
   "source": [
    "df2=np.copy(df)\n",
    "df2=np.append(df2,empty_col,1)\n",
    "print(df2.shape)\n",
    "for j in range(length):\n",
    "    count=0\n",
    "    text_list=df[j,1]\n",
    "    for word in text_list:\n",
    "        if word in personal_pronoun:\n",
    "            count+=1\n",
    "    df2[j,2]=count           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a8b7244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[list(['drinks', 'were', 'bad', 'the', 'hot', 'chocolate', 'was', 'watered', 'down', 'and', 'the', 'latte', 'had', 'a', 'burnt', 'taste', 'to', 'it', 'the', 'food', 'was', 'also', 'poor', 'quality', 'but', 'the', 'service', 'was', 'the', 'worst', 'part', 'their', 'cashier', 'was', 'very', 'rude'])\n",
      "  1]\n",
      " [list(['this', 'was', 'the', 'worst', 'experience', 'i', 'have', 'ever', 'had', 'a', 'casual', 'coffee', 'light', 'fare', 'place', 'the', 'server', 'disappeared', 'for', 'minutes', 'just', 'talking', 'to', 'his', 'friend', 'by', 'the', 'window', 'as', 'my', 'girlfriend', 'and', 'i', 'sat', 'dumbfounded', 'that', 'this', 'dude', 'had', 'the', 'nerve', 'to', 'do', 'that', 'on', 'the', 'job', 'we', 'are', 'trying', 'to', 'make', 'eye', 'contact', 'but', 'clearly', 'getting', 'paid', 'to', 'talk', 'to', 'his', 'bud', 'was', 'more', 'important', 'to', 'him', 'my', 'girlfriend', 'went', 'up', 'to', 'the', 'counter', 'once', 'the', 'server', 'disappeared', 'into', 'the', 'back', 'for', 'another', 'minutes', 'what', 'is', 'this', 'guy', 'doing', 'and', 'asked', 'if', 'she', 'should', 'order', 'food', 'up', 'there', 'or', 'something', 'the', 'girl', 'at', 'the', 'counter', 'gives', 'her', 'a', 'weird', 'look', 'and', 'just', 'says', 'i', 'will', 'get', 'your', 'server', 'when', 'they', 'arrive', 'from', 'the', 'back', 'they', 'look', 'over', 'at', 'our', 'table', 'and', 'have', 'a', 'laugh', 'yeah', 'leaving', 'us', 'hanging', 'for', 'half', 'a', 'goddamn', 'hour', 'at', 'a', 'place', 'with', 'only', 'two', 'other', 'customers', 'is', 'not', 'funny', 'but', 'in', 'retrospect', 'your', 'collective', 'incompetence', 'and', 'false', 'sense', 'of', 'entitlement', 'certainly', 'was', 'the', 'food', 'was', 'okay', 'for', 'a', 'place', 'called', 'toast', 'i', 'had', 'figured', 'the', 'bread', 'would', 'be', 'better', 'but', 'it', 'was', 'just', 'cold', 'le', 'bus', 'additionally', 'i', 'am', 'sure', 'the', 'andouille', 'in', 'my', 'special', 'was', 'just', 'a', 'link', 'of', 'the', 'pre', 'packaged', 'offering', 'from', 'trader', 'joe', 'is', 'cut', 'into', 'four', 'pieces', 'for', 'unapologetic', 'mediocrity', 'will', 'not', 'be', 'happening', 'again', 'avoid', 'this', 'place', 'like', 'the', 'plague', 'i', 'almost', 'did', 'not', 'leave', 'a', 'tip', 'and', 'honestly', 'i', 'should', 'not', 'have', 'i', 'felt', 'the', 'buyer', 'is', 'remorse', 'all', 'day', 'what', 'a', 'disgrace'])\n",
      "  16]\n",
      " [list(['this', 'is', 'located', 'on', 'the', 'site', 'of', 'the', 'old', 'spruce', 'street', 'video', 'the', 'mild', 'cofee', 'is', 'very', 'good', 'and', 'the', 'pastris', 'are', 'great', 'at', 'times', 'the', 'service', 'is', 'slow', 'even', 'when', 'it', 'is', 'not', 'busy', 'and', 'at', 'other', 'times', 'some', 'patrons', 'receive', 'a', 'complimentary', 'mimosa', 'drink', 'the', 'wifi', 'is', 'good'])\n",
      "  1]\n",
      " ...\n",
      " [list(['stopped', 'by', 'this', 'restaurant', 'yesterday', 'we', 'just', 'wanted', 'a', 'quick', 'sandwich', 'the', 'service', 'was', 'quick', 'i', 'have', 'to', 'say', 'i', 'thought', 'the', 'prices', 'were', 'too', 'high', 'the', 'portions', 'were', 'huge', 'my', 'sub', 'which', 'was', 'roast', 'beef', 'and', 'cheese', 'was', 'very', 'bland', 'what', 'i', 'remember', 'most', 'about', 'this', 'sandwich', 'shop', 'was', 'that', 'it', 'was', 'extremely', 'dirty', 'the', 'dinning', 'area', 'had', 'the', 'most', 'filthy', 'carpet', 'i', 'have', 'ever', 'seen', 'also', 'it', 'looked', 'as', 'though', 'the', 'roof', 'was', 'leaking', 'as', 'several', 'ceiling', 'tiles', 'were', 'water', 'stained', 'just', 'overall', 'the', 'place', 'could', 'use', 'soap', 'and', 'water', 'along', 'with', 'some', 'elbow', 'grease', 'i', 'am', 'not', 'sure', 'what', 'kind', 'of', 'health', 'inspection', 'the', 'state', 'of', 'new', 'hampshire', 'has', 'it', 'would', 'appear', 'it', 'is', 'non', 'existent', 'i', 'would', 'strongly', 'recommend', 'they', 'pay', 'a', 'visit', 'to', 'this', 'sub', 'shop', 'very', 'soon', 'i', 'will', 'not', 'visit', 'again'])\n",
      "  13]\n",
      " [list(['finally', 'checked', 'out', 'the', 'best', 'subs', 'in', 'claremont', 'nh', 'today', 'and', 'it', 'was', 'really', 'good', 'had', 'a', 'turkey', 'on', 'toasted', 'white', 'sandwich', 'lots', 'of', 'choices', 'and', 'the', 'subs', 'look', 'humongous', 'i', 'went', 'for', 'the', 'smaller', 'sandwich', 'size', 'which', 'was', 'still', 'really', 'big', 'there', 'are', 'not', 'many', 'independent', 'sub', 'shops', 'left', 'but', 'this', 'one', 'will', 'continue', 'to', 'get', 'my', 'business'])\n",
      "  2]\n",
      " [list(['just', 'got', 'me', 'some', 'best', 'subs', 'and', 'i', 'got', 'ta', 'say', 'i', 'am', 'a', 'fan', 'the', 'prices', 'are', 'pretty', 'low', 'and', 'the', 'portions', 'are', 'huge', 'the', 'sub', 'i', 'got', 'was', 'as', 'big', 'as', 'the', 'box', 'my', 'fries', 'came', 'in', 'i', 'got', 'a', 'cheeseburger', 'sub', 'with', 'a', 'small', 'fry', 'and', 'a', 'soda', 'for', 'beans', 'it', 'was', 'so', 'much', 'food', 'i', 'could', 'not', 'come', 'near', 'finishing', 'it', 'check', 'this', 'place', 'out', 'it', 'is', 'one', 'of', 'the', 'better', 'sub', 'places', 'in', 'town'])\n",
      "  9]]\n"
     ]
    }
   ],
   "source": [
    "print(df2[:,1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12c389e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import savetxt\n",
    "savetxt(\"feature_personal_pronoun.txt\",df2[:,1:3],fmt=\"%s\",delimiter=\"\\t\",encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1349441d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
