{"cells":[{"cell_type":"code","source":["import pyspark\nfrom pyspark.sql import SparkSession\nfrom pyspark.context import SparkContext\nfrom pyspark.sql import SQLContext\nfrom pyspark.sql.functions import udf, col, lower, regexp_replace\nfile_review=\"/FileStore/tables/features_with_label02.txt\"\nsc = SparkContext.getOrCreate()\nspark = SQLContext(sc)\ndf = spark.read.option(\"sep\",\"\\t\").csv(file_review)\ndf=df.select(col(\"_c0\").cast(\"int\").alias(\"num_of_words\"),col(\"_c1\").cast(\"int\").alias(\"num_of_verbs\"),col(\"_c2\").cast(\"float\").alias(\"avg_word_length\"),\n            col(\"_c3\").cast(\"float\").alias(\"emotiveness_ratio\"),col(\"_c4\").cast(\"int\").alias(\"num_of_posi\"),col(\"_c5\").cast(\"int\").alias(\"num_of_nega\"),\n            col(\"_c6\").cast(\"float\").alias(\"sentiment\"),col(\"_c7\").cast(\"int\").alias(\"label\"))\nfrom pyspark.sql.functions import when\ndf=df.withColumn(\"label\",when(df.label==-1,0).otherwise(1))\ndf=df.toPandas()\nprint(len(df))\n#print(df.head())\n\ndf = spark.createDataFrame(df)\n#df.show(20)\n#df=df[0:10000]\nfrom pyspark.ml.classification import LinearSVC\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml.feature import VectorAssembler\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.datasets import load_breast_cancer\nimport numpy as np\nimport pandas as pd\nfeatures=np.array([\"num_of_words\",\"num_of_verbs\",\"avg_word_length\",\"emotiveness_ratio\",\"num_of_posi\",\"num_of_nega\",\"sentiment\"])\n#print(type(features))\nva=VectorAssembler(inputCols = features, outputCol='features')\nva_df = va.transform(df)\nva_df = va_df.select([\"features\",\"label\"])\nva_df.show(10)\n\n(train, test) = va_df.randomSplit([0.7, 0.3],seed=2)\nprint(train.count())\nprint(test.count())\n# train.show()\n# test.show()\n# test_to_pd=test.toPandas()\n# print(test_to_pd.iloc[0:100,:])\nlsvc = LinearSVC(labelCol=\"label\", maxIter=100)\nlsvc = lsvc.fit(train)\n\npred = lsvc.transform(test)\n#pred.show(3)\nevaluator=MulticlassClassificationEvaluator(metricName=\"accuracy\")\naccuracy = evaluator.evaluate(pred)\n \nprint(\"accuracy score: \", accuracy)\n\ny_pred=pred.select(\"prediction\").collect()\ny_orig=pred.select(\"label\").collect()\n\ntp = pred[(pred.label == 1) & (pred.prediction == 1)].count()\ntn = pred[(pred.label == 0) & (pred.prediction == 0)].count()\nfp = pred[(pred.label == 0) & (pred.prediction == 1)].count()\nfn = pred[(pred.label == 1) & (pred.prediction == 0)].count()\nfake_review_count=pred[pred.label==0].count()\nfake_review_02=test[test.label==0].count()\nprint(fake_review_count)\nprint(fake_review_02)\nprint(\"tp:\",tp)\nprint(\"tn:\",tn)\nprint(\"fp:\",fp)\nprint(\"fn:\",fn)\n\ncm = confusion_matrix(y_orig, y_pred)\nprint(\"Confusion Matrix:\")\nprint(cm) "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f2afeb51-b06d-495e-a7e8-ac3559619b70","inputWidgets":{},"title":""}},"outputs":[{"output_type":"stream","output_type":"stream","name":"stdout","text":["/databricks/spark/python/pyspark/sql/context.py:82: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n  warnings.warn(\n6682913\n+--------------------+-----+\n|            features|label|\n+--------------------+-----+\n|[17.0,2.0,4.88235...|    0|\n|[118.0,21.0,5.533...|    0|\n|[24.0,3.0,5.125,0...|    0|\n|[24.0,3.0,5.125,0...|    0|\n|[24.0,3.0,5.125,0...|    0|\n|[24.0,3.0,5.125,0...|    0|\n|[129.0,15.0,5.651...|    0|\n|[79.0,11.0,5.3544...|    0|\n|[40.0,5.0,5.69999...|    0|\n|[21.0,1.0,6.23809...|    0|\n+--------------------+-----+\nonly showing top 10 rows\n\n4677339\n2005574\naccuracy score:  0.9700315221477741\n60104\n60104\ntp: 1945470\ntn: 0\nfp: 60104\nfn: 0\nConfusion Matrix:\n[[      0   60104]\n [      0 1945470]]\n"]}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Pyspark_YelpZip","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":3801813559618754}},"nbformat":4,"nbformat_minor":0}
