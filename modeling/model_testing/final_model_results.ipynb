{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "729747c6",
   "metadata": {},
   "source": [
    "#### Notebook Summary\n",
    "This notebook contains the code for generating the final training and inferences of our model. It includes some hyperparameter tuning via grid search for the random forest model that we wound up settling on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1ec6f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbe28dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>num_word</th>\n",
       "      <th>num_noun</th>\n",
       "      <th>num_verb</th>\n",
       "      <th>num_adj</th>\n",
       "      <th>num_adv</th>\n",
       "      <th>num_personal_pronoun</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>...</th>\n",
       "      <th>user_content_similarity</th>\n",
       "      <th>positive_reviews</th>\n",
       "      <th>negative_reviews</th>\n",
       "      <th>positive_review_ratio</th>\n",
       "      <th>negative_review_ratio</th>\n",
       "      <th>avg_business_sentiment</th>\n",
       "      <th>avg_business_rating</th>\n",
       "      <th>total_business_reviews</th>\n",
       "      <th>lemma</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5044</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.141963</td>\n",
       "      <td>3.613636</td>\n",
       "      <td>88</td>\n",
       "      <td>drink bad hot chocolate water latte burn taste...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5045</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>241</td>\n",
       "      <td>54</td>\n",
       "      <td>31</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>5.561905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.141963</td>\n",
       "      <td>3.613636</td>\n",
       "      <td>88</td>\n",
       "      <td>bad experience casual coffee light fare place ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5046</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>49</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5.130435</td>\n",
       "      <td>...</td>\n",
       "      <td>4.074681e-02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.141963</td>\n",
       "      <td>3.613636</td>\n",
       "      <td>88</td>\n",
       "      <td>locate site old spruce st video mild cofee goo...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5047</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>216</td>\n",
       "      <td>56</td>\n",
       "      <td>33</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>5.941176</td>\n",
       "      <td>...</td>\n",
       "      <td>4.440892e-16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.141963</td>\n",
       "      <td>3.613636</td>\n",
       "      <td>88</td>\n",
       "      <td>enjoy coffee breakfast twice toast recent visi...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5048</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>146</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>5.507246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.141963</td>\n",
       "      <td>3.613636</td>\n",
       "      <td>88</td>\n",
       "      <td>love toast food choice fantastic love serve br...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  business_id  rating  num_word  num_noun  num_verb  num_adj  \\\n",
       "0     5044            0     1.0        35         9         2        5   \n",
       "1     5045            0     1.0       241        54        31       16   \n",
       "2     5046            0     3.0        49        11         3        9   \n",
       "3     5047            0     5.0       216        56        33       19   \n",
       "4     5048            0     5.0       146        31        23       15   \n",
       "\n",
       "   num_adv  num_personal_pronoun  avg_word_len  ...  user_content_similarity  \\\n",
       "0        2                     1      5.000000  ...             0.000000e+00   \n",
       "1       15                     7      5.561905  ...             0.000000e+00   \n",
       "2        2                     1      5.130435  ...             4.074681e-02   \n",
       "3       14                     5      5.941176  ...             4.440892e-16   \n",
       "4        9                     8      5.507246  ...             0.000000e+00   \n",
       "\n",
       "   positive_reviews  negative_reviews  positive_review_ratio  \\\n",
       "0               0.0               1.0                   0.00   \n",
       "1               0.0               1.0                   0.00   \n",
       "2               1.0               0.0                   0.25   \n",
       "3               1.0               0.0                   1.00   \n",
       "4               1.0               0.0                   1.00   \n",
       "\n",
       "   negative_review_ratio  avg_business_sentiment  avg_business_rating  \\\n",
       "0                    1.0                0.141963             3.613636   \n",
       "1                    1.0                0.141963             3.613636   \n",
       "2                    0.0                0.141963             3.613636   \n",
       "3                    0.0                0.141963             3.613636   \n",
       "4                    0.0                0.141963             3.613636   \n",
       "\n",
       "   total_business_reviews                                              lemma  \\\n",
       "0                      88  drink bad hot chocolate water latte burn taste...   \n",
       "1                      88  bad experience casual coffee light fare place ...   \n",
       "2                      88  locate site old spruce st video mild cofee goo...   \n",
       "3                      88  enjoy coffee breakfast twice toast recent visi...   \n",
       "4                      88  love toast food choice fantastic love serve br...   \n",
       "\n",
       "   label  \n",
       "0     -1  \n",
       "1     -1  \n",
       "2     -1  \n",
       "3     -1  \n",
       "4     -1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/yelp_training/yelp_zip_processed_features.csv', sep='\\t')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "431fb7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_feature_columns = ['rating', 'lexical_diversity', 'sentiment', 'emotiveness_ratio',\n",
    "                           'num_negative_words', 'num_clauses',\n",
    "                           'previous_user_reviews', 'avg_user_sentiment',\n",
    "                           'total_user_reviews', 'user_content_similarity', 'positive_reviews',\n",
    "                           'negative_reviews', 'negative_review_ratio', 'avg_business_sentiment',\n",
    "                           'avg_business_rating', 'total_business_reviews']\n",
    "text_feature_columns = ['lemma']\n",
    "id_columns = ['user_id', 'business_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c831856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(608463, 31)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_lemma = df['lemma'].isna()\n",
    "filtered_df = df[~null_lemma]\n",
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f8e880d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(425924, 17)\n",
      "(182539, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Data_Science_Studies\\GTech\\.venv\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.28      0.63      0.38     24077\n",
      "           1       0.93      0.75      0.83    158462\n",
      "\n",
      "    accuracy                           0.73    182539\n",
      "   macro avg       0.60      0.69      0.61    182539\n",
      "weighted avg       0.84      0.73      0.77    182539\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 15138,   8939],\n",
       "       [ 39595, 118867]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVC\n",
    "X_train, X_test, y_train, y_test = train_test_split(filtered_df[numeric_feature_columns + text_feature_columns],\n",
    "                                                    filtered_df['label'].values,\n",
    "                                                    test_size=.3,\n",
    "                                                    random_state=24)\n",
    "resampler = SMOTE(random_state=24, k_neighbors=3)\n",
    "summary_pipeline = Pipeline([('scaler', StandardScaler())])\n",
    "tfidf_pipeline = Pipeline([('vectorizer', TfidfVectorizer(analyzer='word', ngram_range=(1,1)))])\n",
    "column_processor = ColumnTransformer([('summary', summary_pipeline, numeric_feature_columns),\n",
    "                                      ('tfidf', tfidf_pipeline, 'lemma')])\n",
    "\n",
    "svm = LinearSVC()\n",
    "\n",
    "svm_pipeline = Pipeline([('preprocessing', column_processor),\n",
    "                         ('upsampler', resampler),\n",
    "                         ('svc', svm)])\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "svm_pipeline.fit(X_train, y_train)\n",
    "svm_preds = svm_pipeline.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, svm_preds))\n",
    "metrics.confusion_matrix(y_test, svm_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3949774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(425924, 17)\n",
      "(182539, 17)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.31      0.61      0.41     24077\n",
      "           1       0.93      0.80      0.86    158462\n",
      "\n",
      "    accuracy                           0.77    182539\n",
      "   macro avg       0.62      0.70      0.63    182539\n",
      "weighted avg       0.85      0.77      0.80    182539\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 14609,   9468],\n",
       "       [ 32439, 126023]], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RF\n",
    "X_train, X_test, y_train, y_test = train_test_split(filtered_df[numeric_feature_columns + text_feature_columns],\n",
    "                                                    filtered_df['label'].values,\n",
    "                                                    test_size=.3,\n",
    "                                                    random_state=24)\n",
    "resampler = SMOTE(random_state=24, k_neighbors=3)\n",
    "summary_pipeline = Pipeline([('scaler', StandardScaler())])\n",
    "tfidf_pipeline = Pipeline([('vectorizer', TfidfVectorizer(analyzer='word', ngram_range=(1,1)))])\n",
    "column_processor = ColumnTransformer([('summary', summary_pipeline, numeric_feature_columns),\n",
    "                                      ('tfidf', tfidf_pipeline, 'lemma')])\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=150, min_samples_leaf=1, max_samples=.5, max_depth=20)\n",
    "\n",
    "rf_pipeline = Pipeline([('preprocessing', column_processor),\n",
    "                         ('upsampler', resampler),\n",
    "                         ('rf', rf)])\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "rf_preds = rf_pipeline.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, rf_preds))\n",
    "metrics.confusion_matrix(y_test, rf_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62974b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_final_model.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(rf_pipeline, 'rf_final_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebad2617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    0.731871\n",
       "-1    0.268129\n",
       "Name: labels, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'labels': rf_preds}).labels.value_counts()/rf_preds.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4953e91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'max_depth': [5, 10, 15, 20],\n",
    "          'min_samples_leaf': [1, 5, .01],\n",
    "          'n_estimators': [100, 150]}\n",
    "\n",
    "rf = RandomForestClassifier(max_samples=.5)\n",
    "gs_rf = GridSearchCV(estimator=rf, param_grid=params, n_jobs=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94559b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 55.74729972,  81.7218997 ,  54.69330006,  81.87800169,\n",
       "         28.98100147,  40.86236019, 117.88440075, 173.28810005,\n",
       "        110.08240056, 169.20730124,  28.55430064,  43.83959928,\n",
       "        215.84879227, 322.27450013, 188.35630016, 287.63340006,\n",
       "         27.95050001,  42.56709957, 379.90850062, 537.38480072,\n",
       "        260.70720048, 338.35539994,  26.02040195,  36.30100102]),\n",
       " 'std_fit_time': array([ 0.91172944,  1.87029312,  1.24191298,  2.4994744 ,  1.27264193,\n",
       "         1.36705373,  1.21610049,  4.38253972,  1.98068291,  4.19380972,\n",
       "         1.62069638,  0.56915327,  1.82042726,  4.13854198,  1.83901993,\n",
       "         3.24925451,  1.53346758,  2.02647757,  6.42811265, 27.09273694,\n",
       "        14.592427  , 22.41697156,  1.36941765,  2.43445648]),\n",
       " 'mean_score_time': array([4.92740059, 6.71830225, 4.79919968, 7.237885  , 4.65209823,\n",
       "        6.56549993, 4.70179958, 6.76030059, 4.50979886, 7.03919811,\n",
       "        4.22009997, 6.2218996 , 4.90879998, 7.572399  , 5.0721015 ,\n",
       "        7.6672997 , 4.26169991, 6.38040042, 5.58150034, 7.55939927,\n",
       "        4.80329995, 6.52889981, 3.90140009, 5.38159862]),\n",
       " 'std_score_time': array([0.40976231, 0.52695138, 0.31388097, 0.74326301, 0.39426451,\n",
       "        0.56599936, 0.38975013, 0.48257073, 0.30894605, 0.57409585,\n",
       "        0.27627953, 0.42911531, 0.32605175, 0.44131825, 0.49437237,\n",
       "        0.34246288, 0.26492153, 0.48744806, 0.34731307, 0.50386249,\n",
       "        0.32136534, 0.73202957, 0.30285703, 0.31580601]),\n",
       " 'param_max_depth': masked_array(data=[5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 15, 15, 15,\n",
       "                    15, 15, 15, 20, 20, 20, 20, 20, 20],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[1, 1, 5, 5, 0.01, 0.01, 1, 1, 5, 5, 0.01, 0.01, 1, 1,\n",
       "                    5, 5, 0.01, 0.01, 1, 1, 5, 5, 0.01, 0.01],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[100, 150, 100, 150, 100, 150, 100, 150, 100, 150, 100,\n",
       "                    150, 100, 150, 100, 150, 100, 150, 100, 150, 100, 150,\n",
       "                    100, 150],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 5, 'min_samples_leaf': 1, 'n_estimators': 100},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 1, 'n_estimators': 150},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 5, 'n_estimators': 100},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 5, 'n_estimators': 150},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 0.01, 'n_estimators': 100},\n",
       "  {'max_depth': 5, 'min_samples_leaf': 0.01, 'n_estimators': 150},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 1, 'n_estimators': 100},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 1, 'n_estimators': 150},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 5, 'n_estimators': 100},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 5, 'n_estimators': 150},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 0.01, 'n_estimators': 100},\n",
       "  {'max_depth': 10, 'min_samples_leaf': 0.01, 'n_estimators': 150},\n",
       "  {'max_depth': 15, 'min_samples_leaf': 1, 'n_estimators': 100},\n",
       "  {'max_depth': 15, 'min_samples_leaf': 1, 'n_estimators': 150},\n",
       "  {'max_depth': 15, 'min_samples_leaf': 5, 'n_estimators': 100},\n",
       "  {'max_depth': 15, 'min_samples_leaf': 5, 'n_estimators': 150},\n",
       "  {'max_depth': 15, 'min_samples_leaf': 0.01, 'n_estimators': 100},\n",
       "  {'max_depth': 15, 'min_samples_leaf': 0.01, 'n_estimators': 150},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 1, 'n_estimators': 100},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 1, 'n_estimators': 150},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 5, 'n_estimators': 100},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 5, 'n_estimators': 150},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 0.01, 'n_estimators': 100},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 0.01, 'n_estimators': 150}],\n",
       " 'split0_test_score': array([0.68198391, 0.68682058, 0.68911377, 0.67532081, 0.67890603,\n",
       "        0.63697921, 0.69965298, 0.70041061, 0.70634314, 0.72200313,\n",
       "        0.70881897, 0.71780909, 0.71396005, 0.71071982, 0.70452347,\n",
       "        0.71870878, 0.66200137, 0.69503954, 0.73123   , 0.73315114,\n",
       "        0.72423543, 0.72830094, 0.725541  , 0.69690656]),\n",
       " 'split1_test_score': array([0.79849015, 0.78854623, 0.79154293, 0.78910769, 0.79146852,\n",
       "        0.78707155, 0.79326113, 0.81770153, 0.81099784, 0.81632833,\n",
       "        0.78333074, 0.77391446, 0.8210297 , 0.82134764, 0.81733625,\n",
       "        0.82422935, 0.78095638, 0.78629362, 0.82594078, 0.8290119 ,\n",
       "        0.81651097, 0.82787545, 0.77503737, 0.79956571]),\n",
       " 'split2_test_score': array([0.78233488, 0.7875504 , 0.77937197, 0.79290121, 0.77072003,\n",
       "        0.7742241 , 0.80941364, 0.80669427, 0.81609032, 0.82259112,\n",
       "        0.77465703, 0.77285088, 0.81871499, 0.80863571, 0.81232243,\n",
       "        0.81887734, 0.77908786, 0.80783749, 0.8261696 , 0.83170982,\n",
       "        0.81782883, 0.81440593, 0.78102254, 0.7736694 ]),\n",
       " 'split3_test_score': array([0.78845009, 0.80279108, 0.79999729, 0.80863571, 0.77624672,\n",
       "        0.79624293, 0.80664691, 0.8128433 , 0.80588251, 0.81446681,\n",
       "        0.78205753, 0.78510837, 0.81258625, 0.82812458, 0.81837   ,\n",
       "        0.82142761, 0.7829234 , 0.78661011, 0.83595801, 0.83199394,\n",
       "        0.82103526, 0.83480126, 0.77212707, 0.77987255]),\n",
       " 'split4_test_score': array([0.80638986, 0.79428796, 0.78393809, 0.80034229, 0.77540791,\n",
       "        0.77450821, 0.80362313, 0.82363964, 0.81669914, 0.80935276,\n",
       "        0.75755608, 0.79021566, 0.82108261, 0.83200747, 0.81381741,\n",
       "        0.81260654, 0.76220337, 0.77824905, 0.83051249, 0.82062938,\n",
       "        0.82578402, 0.82449874, 0.74830885, 0.79383473]),\n",
       " 'mean_test_score': array([0.77152978, 0.77199925, 0.76879281, 0.77326154, 0.75854984,\n",
       "        0.7538052 , 0.78251956, 0.79225787, 0.79120259, 0.79694843,\n",
       "        0.76128407, 0.76797969, 0.79747472, 0.80016704, 0.79327391,\n",
       "        0.79916992, 0.75343447, 0.77080596, 0.80996218, 0.80929924,\n",
       "        0.8010789 , 0.80597646, 0.76040736, 0.76876979]),\n",
       " 'std_test_score': array([0.04552713, 0.04293243, 0.0404508 , 0.04942449, 0.04042836,\n",
       "        0.05899401, 0.04179242, 0.04626075, 0.04260974, 0.03771124,\n",
       "        0.02779537, 0.02593788, 0.04187213, 0.04542373, 0.04443047,\n",
       "        0.04041361, 0.04630778, 0.03913291, 0.03953442, 0.03829563,\n",
       "        0.03855445, 0.03939049, 0.02068048, 0.03711668]),\n",
       " 'rank_test_score': array([15, 14, 17, 13, 22, 23, 12, 10, 11,  8, 20, 19,  7,  5,  9,  6, 24,\n",
       "        16,  1,  2,  4,  3, 21, 18])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pipeline[2].cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "faae5d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(425924, 19)\n",
      "(182539, 19)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.31      0.62      0.42     24077\n",
      "           1       0.93      0.80      0.86    158462\n",
      "\n",
      "    accuracy                           0.77    182539\n",
      "   macro avg       0.62      0.71      0.64    182539\n",
      "weighted avg       0.85      0.77      0.80    182539\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 14899,   9178],\n",
       "       [ 32414, 126048]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Random Forest\n",
    "X_train, X_test, y_train, y_test = train_test_split(filtered_df[numeric_feature_columns + text_feature_columns],\n",
    "                                                    filtered_df['label'].values,\n",
    "                                                    test_size=.3,\n",
    "                                                    random_state=24)\n",
    "resampler = SMOTE(random_state=24, k_neighbors=3)\n",
    "summary_pipeline = Pipeline([('scaler', StandardScaler())])\n",
    "tfidf_pipeline = Pipeline([('vectorizer', TfidfVectorizer(analyzer='word', ngram_range=(1,1)))])\n",
    "column_processor = ColumnTransformer([('summary', summary_pipeline, numeric_feature_columns),\n",
    "                                      ('tfidf', tfidf_pipeline, 'lemma')])\n",
    "\n",
    "params = {'max_depth': [15, 20],\n",
    "          'min_samples_leaf': [1, 3],\n",
    "          'n_estimators': [100, 150]}\n",
    "\n",
    "rf = RandomForestClassifier(max_samples=.5)\n",
    "gs_rf = GridSearchCV(estimator=rf, param_grid=params, scoring='f1_macro', n_jobs=8)\n",
    "\n",
    "rf_pipeline = Pipeline([('preprocessing', column_processor),\n",
    "                         ('upsampler', resampler),\n",
    "                         ('classifier', gs_rf)])\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "rf_preds = rf_pipeline.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, rf_preds))\n",
    "metrics.confusion_matrix(y_test, rf_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90f2a305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([205.0421979 , 287.88299932, 168.17559829, 283.4786983 ,\n",
       "        395.14619951, 594.30439925, 321.23929925, 402.842098  ]),\n",
       " 'std_fit_time': array([ 2.1034299 , 11.12232475,  1.48808441, 11.94609093,  6.29080794,\n",
       "         4.9794179 ,  7.85330146, 29.63495146]),\n",
       " 'mean_score_time': array([4.70269961, 6.44900603, 4.44300098, 7.47850037, 5.48090148,\n",
       "        8.33510137, 5.3878005 , 6.80299959]),\n",
       " 'std_score_time': array([0.40887997, 0.3938286 , 0.26314798, 0.38967014, 0.351193  ,\n",
       "        0.33285412, 0.39357054, 0.5549497 ]),\n",
       " 'param_max_depth': masked_array(data=[15, 15, 15, 15, 20, 20, 20, 20],\n",
       "              mask=[False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[1, 1, 3, 3, 1, 1, 3, 3],\n",
       "              mask=[False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[100, 150, 100, 150, 100, 150, 100, 150],\n",
       "              mask=[False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 15, 'min_samples_leaf': 1, 'n_estimators': 100},\n",
       "  {'max_depth': 15, 'min_samples_leaf': 1, 'n_estimators': 150},\n",
       "  {'max_depth': 15, 'min_samples_leaf': 3, 'n_estimators': 100},\n",
       "  {'max_depth': 15, 'min_samples_leaf': 3, 'n_estimators': 150},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 1, 'n_estimators': 100},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 1, 'n_estimators': 150},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 3, 'n_estimators': 100},\n",
       "  {'max_depth': 20, 'min_samples_leaf': 3, 'n_estimators': 150}],\n",
       " 'split0_test_score': array([0.72536264, 0.71179066, 0.71976487, 0.7078303 , 0.71747453,\n",
       "        0.72507775, 0.72586736, 0.72543453]),\n",
       " 'split1_test_score': array([0.81225101, 0.82065014, 0.80662591, 0.8268714 , 0.83784454,\n",
       "        0.83176778, 0.82398485, 0.82697254]),\n",
       " 'split2_test_score': array([0.81354109, 0.81786178, 0.81528339, 0.82105545, 0.83797955,\n",
       "        0.82722096, 0.81323046, 0.82007894]),\n",
       " 'split3_test_score': array([0.82078033, 0.82146085, 0.80850716, 0.82661224, 0.81802427,\n",
       "        0.82988638, 0.82097585, 0.82796605]),\n",
       " 'split4_test_score': array([0.82868924, 0.82728752, 0.80647891, 0.80684412, 0.82767891,\n",
       "        0.83025723, 0.82501211, 0.82524173]),\n",
       " 'mean_test_score': array([0.80012486, 0.79981019, 0.79133205, 0.7978427 , 0.80780036,\n",
       "        0.80884202, 0.80181413, 0.80513876]),\n",
       " 'std_test_score': array([0.03783914, 0.04411656, 0.03592727, 0.04559044, 0.04576434,\n",
       "        0.04190777, 0.03819713, 0.03994472]),\n",
       " 'rank_test_score': array([5, 6, 8, 7, 2, 1, 4, 3])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pipeline[2].cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2342894f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(425924, 19)\n",
      "(182539, 19)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.32      0.59      0.42     24077\n",
      "           1       0.93      0.81      0.87    158462\n",
      "\n",
      "    accuracy                           0.78    182539\n",
      "   macro avg       0.63      0.70      0.64    182539\n",
      "weighted avg       0.85      0.78      0.81    182539\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 14282,   9795],\n",
       "       [ 29703, 128759]], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Random Forest\n",
    "X_train, X_test, y_train, y_test = train_test_split(filtered_df[numeric_feature_columns + text_feature_columns],\n",
    "                                                    filtered_df['label'].values,\n",
    "                                                    test_size=.3,\n",
    "                                                    random_state=24)\n",
    "resampler = SMOTE(random_state=24, k_neighbors=3)\n",
    "summary_pipeline = Pipeline([('scaler', StandardScaler())])\n",
    "tfidf_pipeline = Pipeline([('vectorizer', TfidfVectorizer(analyzer='word', ngram_range=(1,1)))])\n",
    "column_processor = ColumnTransformer([('summary', summary_pipeline, numeric_feature_columns),\n",
    "                                      ('tfidf', tfidf_pipeline, 'lemma')])\n",
    "\n",
    "params = {'max_depth': [20, 30]}\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=150, min_samples_leaf=1, max_samples=.5)\n",
    "gs_rf = GridSearchCV(estimator=rf, param_grid=params, scoring='f1', n_jobs=5)\n",
    "\n",
    "rf_pipeline = Pipeline([('preprocessing', column_processor),\n",
    "                         ('upsampler', resampler),\n",
    "                         ('classifier', gs_rf)])\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "rf_preds = rf_pipeline.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, rf_preds))\n",
    "metrics.confusion_matrix(y_test, rf_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c3e1ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([380.4331017 , 892.77549839]),\n",
       " 'std_fit_time': array([ 2.23868168, 13.83918291]),\n",
       " 'mean_score_time': array([7.07489963, 7.57670135]),\n",
       " 'std_score_time': array([0.35750201, 0.72704709]),\n",
       " 'param_max_depth': masked_array(data=[20, 30],\n",
       "              mask=[False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 20}, {'max_depth': 30}],\n",
       " 'split0_test_score': array([0.75673856, 0.77343559]),\n",
       " 'split1_test_score': array([0.82378117, 0.84274131]),\n",
       " 'split2_test_score': array([0.81364059, 0.83041676]),\n",
       " 'split3_test_score': array([0.81493317, 0.84867518]),\n",
       " 'split4_test_score': array([0.81002915, 0.84084648]),\n",
       " 'mean_test_score': array([0.80382453, 0.82722306]),\n",
       " 'std_test_score': array([0.02397336, 0.02753143]),\n",
       " 'rank_test_score': array([2, 1])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pipeline[2].cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61961238",
   "metadata": {},
   "source": [
    "The RFC has clearly outperformed the SVC, improving on every metric primarily by reducing the number of false negatives. With this in mind, it's time to generate new inferences on our true data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de734f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;summary&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;rating&#x27;,\n",
       "                                                   &#x27;lexical_diversity&#x27;,\n",
       "                                                   &#x27;sentiment&#x27;,\n",
       "                                                   &#x27;emotiveness_ratio&#x27;,\n",
       "                                                   &#x27;num_negative_words&#x27;,\n",
       "                                                   &#x27;num_clauses&#x27;,\n",
       "                                                   &#x27;previous_user_reviews&#x27;,\n",
       "                                                   &#x27;avg_user_sentiment&#x27;,\n",
       "                                                   &#x27;total_user_reviews&#x27;,\n",
       "                                                   &#x27;user_content_similarity&#x27;,\n",
       "                                                   &#x27;positive_reviews&#x27;,\n",
       "                                                   &#x27;negative_reviews&#x27;,\n",
       "                                                   &#x27;negative_review_ratio&#x27;,\n",
       "                                                   &#x27;avg_business_sentiment&#x27;,\n",
       "                                                   &#x27;avg_business_rating&#x27;,\n",
       "                                                   &#x27;total_business_reviews&#x27;]),\n",
       "                                                 (&#x27;tfidf&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
       "                                                                   TfidfVectorizer())]),\n",
       "                                                  &#x27;lemma&#x27;)])),\n",
       "                (&#x27;upsampler&#x27;, SMOTE(k_neighbors=3, random_state=24)),\n",
       "                (&#x27;rf&#x27;,\n",
       "                 RandomForestClassifier(max_depth=20, max_samples=0.5,\n",
       "                                        n_estimators=150))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;summary&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;rating&#x27;,\n",
       "                                                   &#x27;lexical_diversity&#x27;,\n",
       "                                                   &#x27;sentiment&#x27;,\n",
       "                                                   &#x27;emotiveness_ratio&#x27;,\n",
       "                                                   &#x27;num_negative_words&#x27;,\n",
       "                                                   &#x27;num_clauses&#x27;,\n",
       "                                                   &#x27;previous_user_reviews&#x27;,\n",
       "                                                   &#x27;avg_user_sentiment&#x27;,\n",
       "                                                   &#x27;total_user_reviews&#x27;,\n",
       "                                                   &#x27;user_content_similarity&#x27;,\n",
       "                                                   &#x27;positive_reviews&#x27;,\n",
       "                                                   &#x27;negative_reviews&#x27;,\n",
       "                                                   &#x27;negative_review_ratio&#x27;,\n",
       "                                                   &#x27;avg_business_sentiment&#x27;,\n",
       "                                                   &#x27;avg_business_rating&#x27;,\n",
       "                                                   &#x27;total_business_reviews&#x27;]),\n",
       "                                                 (&#x27;tfidf&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
       "                                                                   TfidfVectorizer())]),\n",
       "                                                  &#x27;lemma&#x27;)])),\n",
       "                (&#x27;upsampler&#x27;, SMOTE(k_neighbors=3, random_state=24)),\n",
       "                (&#x27;rf&#x27;,\n",
       "                 RandomForestClassifier(max_depth=20, max_samples=0.5,\n",
       "                                        n_estimators=150))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessing: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;summary&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;rating&#x27;, &#x27;lexical_diversity&#x27;, &#x27;sentiment&#x27;,\n",
       "                                  &#x27;emotiveness_ratio&#x27;, &#x27;num_negative_words&#x27;,\n",
       "                                  &#x27;num_clauses&#x27;, &#x27;previous_user_reviews&#x27;,\n",
       "                                  &#x27;avg_user_sentiment&#x27;, &#x27;total_user_reviews&#x27;,\n",
       "                                  &#x27;user_content_similarity&#x27;, &#x27;positive_reviews&#x27;,\n",
       "                                  &#x27;negative_reviews&#x27;, &#x27;negative_review_ratio&#x27;,\n",
       "                                  &#x27;avg_business_sentiment&#x27;,\n",
       "                                  &#x27;avg_business_rating&#x27;,\n",
       "                                  &#x27;total_business_reviews&#x27;]),\n",
       "                                (&#x27;tfidf&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
       "                                                  TfidfVectorizer())]),\n",
       "                                 &#x27;lemma&#x27;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">summary</label><div class=\"sk-toggleable__content\"><pre>[&#x27;rating&#x27;, &#x27;lexical_diversity&#x27;, &#x27;sentiment&#x27;, &#x27;emotiveness_ratio&#x27;, &#x27;num_negative_words&#x27;, &#x27;num_clauses&#x27;, &#x27;previous_user_reviews&#x27;, &#x27;avg_user_sentiment&#x27;, &#x27;total_user_reviews&#x27;, &#x27;user_content_similarity&#x27;, &#x27;positive_reviews&#x27;, &#x27;negative_reviews&#x27;, &#x27;negative_review_ratio&#x27;, &#x27;avg_business_sentiment&#x27;, &#x27;avg_business_rating&#x27;, &#x27;total_business_reviews&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">tfidf</label><div class=\"sk-toggleable__content\"><pre>lemma</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE(k_neighbors=3, random_state=24)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=20, max_samples=0.5, n_estimators=150)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 ColumnTransformer(transformers=[('summary',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['rating',\n",
       "                                                   'lexical_diversity',\n",
       "                                                   'sentiment',\n",
       "                                                   'emotiveness_ratio',\n",
       "                                                   'num_negative_words',\n",
       "                                                   'num_clauses',\n",
       "                                                   'previous_user_reviews',\n",
       "                                                   'avg_user_sentiment',\n",
       "                                                   'total_user_reviews',\n",
       "                                                   'user_content_similarity',\n",
       "                                                   'positive_reviews',\n",
       "                                                   'negative_reviews',\n",
       "                                                   'negative_review_ratio',\n",
       "                                                   'avg_business_sentiment',\n",
       "                                                   'avg_business_rating',\n",
       "                                                   'total_business_reviews']),\n",
       "                                                 ('tfidf',\n",
       "                                                  Pipeline(steps=[('vectorizer',\n",
       "                                                                   TfidfVectorizer())]),\n",
       "                                                  'lemma')])),\n",
       "                ('upsampler', SMOTE(k_neighbors=3, random_state=24)),\n",
       "                ('rf',\n",
       "                 RandomForestClassifier(max_depth=20, max_samples=0.5,\n",
       "                                        n_estimators=150))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fb331ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>num_word</th>\n",
       "      <th>num_noun</th>\n",
       "      <th>num_verb</th>\n",
       "      <th>num_adj</th>\n",
       "      <th>num_adv</th>\n",
       "      <th>num_personal_pronoun</th>\n",
       "      <th>...</th>\n",
       "      <th>total_user_reviews</th>\n",
       "      <th>user_content_similarity</th>\n",
       "      <th>positive_reviews</th>\n",
       "      <th>negative_reviews</th>\n",
       "      <th>positive_review_ratio</th>\n",
       "      <th>negative_review_ratio</th>\n",
       "      <th>avg_business_sentiment</th>\n",
       "      <th>avg_business_rating</th>\n",
       "      <th>total_business_reviews</th>\n",
       "      <th>lemma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KU_O5udG6zpxOg-VcAEodg</td>\n",
       "      <td>mh_-eMZ6K5RLWhZyISBhwA</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>3</td>\n",
       "      <td>97</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>0.054206</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.08927</td>\n",
       "      <td>3.068571</td>\n",
       "      <td>175</td>\n",
       "      <td>decide eat aware go hour begin end try multipl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jHmqmoEI-78BGHFJaDKlhQ</td>\n",
       "      <td>5EGs7LX3Z8ZogvOOgNLsnA</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>0.025516</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.08927</td>\n",
       "      <td>3.068571</td>\n",
       "      <td>175</td>\n",
       "      <td>excellent food slow slow slow staff need train...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vwIXZHod-jQmGFvx0wCqSg</td>\n",
       "      <td>q3Kv3wFOwu1Rd2I6T_VWOQ</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>5</td>\n",
       "      <td>62</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0.023194</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.08927</td>\n",
       "      <td>3.068571</td>\n",
       "      <td>175</td>\n",
       "      <td>read ton mixed review fiancé decide try turnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SP32nOhRm-KRAjYMPgf_MQ</td>\n",
       "      <td>wmqsehbFirZPlAluJUakeQ</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>3</td>\n",
       "      <td>79</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>375</td>\n",
       "      <td>0.106651</td>\n",
       "      <td>182.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.485333</td>\n",
       "      <td>0.154667</td>\n",
       "      <td>0.08927</td>\n",
       "      <td>3.068571</td>\n",
       "      <td>175</td>\n",
       "      <td>stop lunch sit afternoon luckily seat fairly q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fvu5n5shkAJDbQjulKNuqw</td>\n",
       "      <td>NMLvjdY7IOdtfU0TepvUuA</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>2</td>\n",
       "      <td>251</td>\n",
       "      <td>60</td>\n",
       "      <td>38</td>\n",
       "      <td>22</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>357</td>\n",
       "      <td>0.023849</td>\n",
       "      <td>180.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.504202</td>\n",
       "      <td>0.165266</td>\n",
       "      <td>0.08927</td>\n",
       "      <td>3.068571</td>\n",
       "      <td>175</td>\n",
       "      <td>want love restaurant interior decorate food lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  KU_O5udG6zpxOg-VcAEodg  mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
       "1  jHmqmoEI-78BGHFJaDKlhQ  5EGs7LX3Z8ZogvOOgNLsnA  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
       "2  vwIXZHod-jQmGFvx0wCqSg  q3Kv3wFOwu1Rd2I6T_VWOQ  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
       "3  SP32nOhRm-KRAjYMPgf_MQ  wmqsehbFirZPlAluJUakeQ  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
       "4  fvu5n5shkAJDbQjulKNuqw  NMLvjdY7IOdtfU0TepvUuA  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
       "\n",
       "   rating  num_word  num_noun  num_verb  num_adj  num_adv  \\\n",
       "0       3        97        12        17       10       12   \n",
       "1       2        23         5         3        5        0   \n",
       "2       5        62        17        11        2        3   \n",
       "3       3        79        23         6        9        3   \n",
       "4       2       251        60        38       22       12   \n",
       "\n",
       "   num_personal_pronoun  ...  total_user_reviews  user_content_similarity  \\\n",
       "0                    10  ...                  28                 0.054206   \n",
       "1                     2  ...                  16                 0.025516   \n",
       "2                     2  ...                   6                 0.023194   \n",
       "3                     1  ...                 375                 0.106651   \n",
       "4                     8  ...                 357                 0.023849   \n",
       "\n",
       "   positive_reviews  negative_reviews  positive_review_ratio  \\\n",
       "0              19.0               3.0               0.678571   \n",
       "1               6.0              10.0               0.375000   \n",
       "2               5.0               1.0               0.833333   \n",
       "3             182.0              58.0               0.485333   \n",
       "4             180.0              59.0               0.504202   \n",
       "\n",
       "   negative_review_ratio  avg_business_sentiment  avg_business_rating  \\\n",
       "0               0.107143                 0.08927             3.068571   \n",
       "1               0.625000                 0.08927             3.068571   \n",
       "2               0.166667                 0.08927             3.068571   \n",
       "3               0.154667                 0.08927             3.068571   \n",
       "4               0.165266                 0.08927             3.068571   \n",
       "\n",
       "   total_business_reviews                                              lemma  \n",
       "0                     175  decide eat aware go hour begin end try multipl...  \n",
       "1                     175  excellent food slow slow slow staff need train...  \n",
       "2                     175  read ton mixed review fiancé decide try turnin...  \n",
       "3                     175  stop lunch sit afternoon luckily seat fairly q...  \n",
       "4                     175  want love restaurant interior decorate food lo...  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df = pd.read_csv('../../data/yelp_all/filtered_preprocessed_dataset.tsv', sep='\\t')\n",
    "null_lemma = all_df['lemma'].isna()\n",
    "filtered_df = all_df[~null_lemma]\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "028f709f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_predictions = rf_pipeline.predict(filtered_df[numeric_feature_columns + text_feature_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09816531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    5481720\n",
       "-1    1508496\n",
       "Name: review_label, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_reviews = pd.DataFrame({'review_id': filtered_df['review_id'], 'review_label': all_predictions})\n",
    "predicted_reviews.review_label.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3b6af94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    0.784199\n",
       "-1    0.215801\n",
       "Name: review_label, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_reviews.review_label.value_counts() / predicted_reviews.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f6849e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_reviews.to_csv('../../data/yelp_all/reviews_with_predicted_label_final_rf.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8def503f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gatech",
   "language": "python",
   "name": "gatech"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
