{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cba28bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aba0c208",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"user_id\", \"product_id\", \"date\", \"full_review\", \"rating\", \"label\", \"word_list\",\n",
    "           \"lemmatized_word_list\", \"num_words\", \"num_verbs\", \"avg_word_len\", \"emotiveness_ratio\",\n",
    "           \"num_positive_words\", \"num_negative_words\", \"sentiment\"]\n",
    "preprocessed_data = pd.read_csv(\"../data/preprocessing and features for modeling/review_features_02.txt\",\n",
    "                                delimiter=\"\\t\",\n",
    "                                names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44d99839",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>date</th>\n",
       "      <th>full_review</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>word_list</th>\n",
       "      <th>lemmatized_word_list</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_verbs</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>emotiveness_ratio</th>\n",
       "      <th>num_positive_words</th>\n",
       "      <th>num_negative_words</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5044</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-11-16</td>\n",
       "      <td>Drinks were bad, the hot chocolate was watered...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>['drinks', 'bad', 'hot', 'chocolate', 'watered...</td>\n",
       "      <td>['drink', 'bad', 'hot', 'chocolate', 'water', ...</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>4.882353</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5045</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-09-08</td>\n",
       "      <td>This was the worst experience I've ever had a ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>['worst', 'experience', 'ive', 'ever', 'casual...</td>\n",
       "      <td>['bad', 'experience', 'ive', 'ever', 'casual',...</td>\n",
       "      <td>118</td>\n",
       "      <td>21</td>\n",
       "      <td>5.533898</td>\n",
       "      <td>0.430380</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.067797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5046</td>\n",
       "      <td>0</td>\n",
       "      <td>2013-10-06</td>\n",
       "      <td>This is located on the site of the old Spruce ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>['located', 'site', 'old', 'spruce', 'st', 'vi...</td>\n",
       "      <td>['locate', 'site', 'old', 'spruce', 'st', 'vid...</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>5.125000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5047</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-11-30</td>\n",
       "      <td>I enjoyed coffee and breakfast twice at Toast ...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>['enjoyed', 'coffee', 'breakfast', 'twice', 't...</td>\n",
       "      <td>['enjoy', 'coffee', 'breakfast', 'twice', 'toa...</td>\n",
       "      <td>129</td>\n",
       "      <td>15</td>\n",
       "      <td>5.651163</td>\n",
       "      <td>0.476744</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>0.124031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5048</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-08-28</td>\n",
       "      <td>I love Toast! The food choices are fantastic -...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>['love', 'toast', 'food', 'choices', 'fantasti...</td>\n",
       "      <td>['love', 'toast', 'food', 'choice', 'fantastic...</td>\n",
       "      <td>79</td>\n",
       "      <td>11</td>\n",
       "      <td>5.354430</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0.151899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608593</th>\n",
       "      <td>119664</td>\n",
       "      <td>5039</td>\n",
       "      <td>2013-01-20</td>\n",
       "      <td>When I first moved to the area I must say I wa...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>['first', 'moved', 'area', 'must', 'say', 'was...</td>\n",
       "      <td>['first', 'move', 'area', 'must', 'say', 'wasn...</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>5.111111</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.185185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608594</th>\n",
       "      <td>56277</td>\n",
       "      <td>5039</td>\n",
       "      <td>2012-11-12</td>\n",
       "      <td>Kind of pricey. I guess I expected a ridiculou...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>['kind', 'pricey', 'guess', 'expected', 'ridic...</td>\n",
       "      <td>['kind', 'pricey', 'guess', 'expect', 'ridicul...</td>\n",
       "      <td>79</td>\n",
       "      <td>9</td>\n",
       "      <td>5.367089</td>\n",
       "      <td>0.396226</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.050633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608595</th>\n",
       "      <td>265320</td>\n",
       "      <td>5039</td>\n",
       "      <td>2012-08-22</td>\n",
       "      <td>Stopped by this restaurant yesterday, we just ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>['stopped', 'restaurant', 'yesterday', 'wanted...</td>\n",
       "      <td>['stop', 'restaurant', 'yesterday', 'want', 'q...</td>\n",
       "      <td>72</td>\n",
       "      <td>10</td>\n",
       "      <td>5.222222</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.069444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608596</th>\n",
       "      <td>161722</td>\n",
       "      <td>5039</td>\n",
       "      <td>2011-05-11</td>\n",
       "      <td>Finally checked out The Best Subs in Claremont...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>['finally', 'checked', 'best', 'subs', 'clarem...</td>\n",
       "      <td>['finally', 'check', 'best', 'sub', 'claremont...</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>5.171429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.057143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608597</th>\n",
       "      <td>78454</td>\n",
       "      <td>5039</td>\n",
       "      <td>2010-07-17</td>\n",
       "      <td>Just got me some \"Best Subs\" and I gotta say, ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>['got', 'best', 'subs', 'got', 'ta', 'say', 'i...</td>\n",
       "      <td>['get', 'best', 'sub', 'get', 'ta', 'say', 'im...</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>4.076923</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>608598 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  product_id        date  \\\n",
       "0          5044           0  2014-11-16   \n",
       "1          5045           0  2014-09-08   \n",
       "2          5046           0  2013-10-06   \n",
       "3          5047           0  2014-11-30   \n",
       "4          5048           0  2014-08-28   \n",
       "...         ...         ...         ...   \n",
       "608593   119664        5039  2013-01-20   \n",
       "608594    56277        5039  2012-11-12   \n",
       "608595   265320        5039  2012-08-22   \n",
       "608596   161722        5039  2011-05-11   \n",
       "608597    78454        5039  2010-07-17   \n",
       "\n",
       "                                              full_review  rating  label  \\\n",
       "0       Drinks were bad, the hot chocolate was watered...     1.0     -1   \n",
       "1       This was the worst experience I've ever had a ...     1.0     -1   \n",
       "2       This is located on the site of the old Spruce ...     3.0     -1   \n",
       "3       I enjoyed coffee and breakfast twice at Toast ...     5.0     -1   \n",
       "4       I love Toast! The food choices are fantastic -...     5.0     -1   \n",
       "...                                                   ...     ...    ...   \n",
       "608593  When I first moved to the area I must say I wa...     4.0      1   \n",
       "608594  Kind of pricey. I guess I expected a ridiculou...     2.0      1   \n",
       "608595  Stopped by this restaurant yesterday, we just ...     1.0      1   \n",
       "608596  Finally checked out The Best Subs in Claremont...     4.0      1   \n",
       "608597  Just got me some \"Best Subs\" and I gotta say, ...     4.0      1   \n",
       "\n",
       "                                                word_list  \\\n",
       "0       ['drinks', 'bad', 'hot', 'chocolate', 'watered...   \n",
       "1       ['worst', 'experience', 'ive', 'ever', 'casual...   \n",
       "2       ['located', 'site', 'old', 'spruce', 'st', 'vi...   \n",
       "3       ['enjoyed', 'coffee', 'breakfast', 'twice', 't...   \n",
       "4       ['love', 'toast', 'food', 'choices', 'fantasti...   \n",
       "...                                                   ...   \n",
       "608593  ['first', 'moved', 'area', 'must', 'say', 'was...   \n",
       "608594  ['kind', 'pricey', 'guess', 'expected', 'ridic...   \n",
       "608595  ['stopped', 'restaurant', 'yesterday', 'wanted...   \n",
       "608596  ['finally', 'checked', 'best', 'subs', 'clarem...   \n",
       "608597  ['got', 'best', 'subs', 'got', 'ta', 'say', 'i...   \n",
       "\n",
       "                                     lemmatized_word_list  num_words  \\\n",
       "0       ['drink', 'bad', 'hot', 'chocolate', 'water', ...         17   \n",
       "1       ['bad', 'experience', 'ive', 'ever', 'casual',...        118   \n",
       "2       ['locate', 'site', 'old', 'spruce', 'st', 'vid...         24   \n",
       "3       ['enjoy', 'coffee', 'breakfast', 'twice', 'toa...        129   \n",
       "4       ['love', 'toast', 'food', 'choice', 'fantastic...         79   \n",
       "...                                                   ...        ...   \n",
       "608593  ['first', 'move', 'area', 'must', 'say', 'wasn...         27   \n",
       "608594  ['kind', 'pricey', 'guess', 'expect', 'ridicul...         79   \n",
       "608595  ['stop', 'restaurant', 'yesterday', 'want', 'q...         72   \n",
       "608596  ['finally', 'check', 'best', 'sub', 'claremont...         35   \n",
       "608597  ['get', 'best', 'sub', 'get', 'ta', 'say', 'im...         39   \n",
       "\n",
       "        num_verbs  avg_word_len  emotiveness_ratio  num_positive_words  \\\n",
       "0               2      4.882353           0.416667                   1   \n",
       "1              21      5.533898           0.430380                   4   \n",
       "2               3      5.125000           0.500000                   4   \n",
       "3              15      5.651163           0.476744                  20   \n",
       "4              11      5.354430           0.500000                  12   \n",
       "...           ...           ...                ...                 ...   \n",
       "608593          5      5.111111           0.625000                   5   \n",
       "608594          9      5.367089           0.396226                   4   \n",
       "608595         10      5.222222           0.675000                   1   \n",
       "608596          4      5.171429           0.571429                   2   \n",
       "608597          5      4.076923           0.480000                   3   \n",
       "\n",
       "        num_negative_words  sentiment  \n",
       "0                        5  -0.235294  \n",
       "1                       12  -0.067797  \n",
       "2                        1   0.125000  \n",
       "3                        4   0.124031  \n",
       "4                        0   0.151899  \n",
       "...                    ...        ...  \n",
       "608593                   0   0.185185  \n",
       "608594                   8  -0.050633  \n",
       "608595                   6  -0.069444  \n",
       "608596                   0   0.057143  \n",
       "608597                   0   0.076923  \n",
       "\n",
       "[608598 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9934e90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model will only include numeric features at this point, so let's filter to relevant columns\n",
    "filtered_features = ['num_words', 'num_verbs', 'avg_word_len', 'emotiveness_ratio',\n",
    "                     'num_positive_words', 'num_negative_words', 'sentiment', 'rating']\n",
    "label_col = 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "686e4995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 11s\n",
      "Wall time: 3min 12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Data_Science_Studies\\GTech\\.venv\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;upsampler&#x27;, SMOTE(k_neighbors=3, random_state=24)),\n",
       "                (&#x27;svc&#x27;, LinearSVC())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;upsampler&#x27;, SMOTE(k_neighbors=3, random_state=24)),\n",
       "                (&#x27;svc&#x27;, LinearSVC())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE(k_neighbors=3, random_state=24)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('upsampler', SMOTE(k_neighbors=3, random_state=24)),\n",
       "                ('svc', LinearSVC())])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# Baseline model without any direct representation of words or word embeddings\n",
    "\n",
    "# Using a linear kernel for now as I have seen pretty good results for linear SVM with text classification\n",
    "# Using LinearSVC for better performance on large data sets\n",
    "baseline_svm = LinearSVC()\n",
    "\n",
    "# Best practice scale data when using geometric based models like SVM where magnitude is important\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Best practice to split the data before scaling, so that the scaler is fit on only the training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(preprocessed_data[filtered_features],\n",
    "                                                    preprocessed_data[label_col].values,\n",
    "                                                    test_size=.3,\n",
    "                                                    random_state=24)\n",
    "\n",
    "# Minority class is significantly less than majority class, so we should use SMOTE to upsample the data\n",
    "resampler = SMOTE(random_state=24, k_neighbors=3)\n",
    "\n",
    "# Using imblearn pipeline to manage the scaling and resampling logic in a simple way\n",
    "svm_pipe = Pipeline([('scaler', scaler),\n",
    "                     ('upsampler', resampler),\n",
    "                     ('svc', baseline_svm)])\n",
    "\n",
    "svm_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b14fdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = svm_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db4f5458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.32999912, -0.15179489, -0.04664113,  0.00379112,  0.08096823,\n",
       "        -0.09776226, -0.09691944,  0.0769002 ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_pipe[2].coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "089d1d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.18      0.66      0.28     24295\n",
      "           1       0.91      0.53      0.67    158285\n",
      "\n",
      "    accuracy                           0.55    182580\n",
      "   macro avg       0.54      0.60      0.48    182580\n",
      "weighted avg       0.81      0.55      0.62    182580\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2865fd54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15971,  8324],\n",
       "       [73947, 84338]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72da806c",
   "metadata": {},
   "source": [
    "Unfortunately, the baseline model with no tuning gives a 55% overall accuracy on the test set. Looking at the confusion matrix, it's clear that the model is misidentifying many of the true reviews as fake reviews. We may need more complex features to represent the differences between the classes, or we could try alternative rebalancing methods to compare."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6f05e6",
   "metadata": {},
   "source": [
    "#### TF-IDF Vectorization\n",
    "Term frequency - inverse document frequency is a common, simple word embedding technique that represents the uniqueness of the terms in a given document. It is the product of the term frequency within a single document with the inverse of the term frequency across the entire corpus. In this case, the training set is very large, so we may run into computational challenges with training an SVM model on a tf-idf vectorized dataset with only local resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b56a8dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF vectorizer with unigram representation (single words within each document)\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit(preprocessed_data.lemmatized_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2039ce9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426018, 323907)\n",
      "(182580, 323907)\n"
     ]
    }
   ],
   "source": [
    "tfidf_svm = LinearSVC()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(preprocessed_data.lemmatized_word_list,\n",
    "                                                    preprocessed_data[label_col].values,\n",
    "                                                    test_size=.3,\n",
    "                                                    random_state=24)\n",
    "\n",
    "# Using imblearn pipeline to manage the resampling logic in a simple way\n",
    "tfidf_svm_pipe = Pipeline([('upsampler', resampler),\n",
    "                           ('svc', tfidf_svm)])\n",
    "\n",
    "tfidf_x_train = vectorizer.transform(X_train)\n",
    "tfidf_x_test = vectorizer.transform(X_test)\n",
    "\n",
    "print(tfidf_x_train.shape)\n",
    "print(tfidf_x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7158308",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 24s\n",
      "Wall time: 2min 26s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;upsampler&#x27;, SMOTE(k_neighbors=3, random_state=24)),\n",
       "                (&#x27;svc&#x27;, LinearSVC())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;upsampler&#x27;, SMOTE(k_neighbors=3, random_state=24)),\n",
       "                (&#x27;svc&#x27;, LinearSVC())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE(k_neighbors=3, random_state=24)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('upsampler', SMOTE(k_neighbors=3, random_state=24)),\n",
       "                ('svc', LinearSVC())])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tfidf_svm_pipe.fit(tfidf_x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4053cae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.26      0.44      0.33     24295\n",
      "           1       0.90      0.81      0.85    158285\n",
      "\n",
      "    accuracy                           0.76    182580\n",
      "   macro avg       0.58      0.62      0.59    182580\n",
      "weighted avg       0.82      0.76      0.78    182580\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 10657,  13638],\n",
       "       [ 30345, 127940]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_preds = tfidf_svm_pipe.predict(tfidf_x_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, tfidf_preds))\n",
    "metrics.confusion_matrix(y_test, tfidf_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a349d529",
   "metadata": {},
   "source": [
    "Simple unigram tf-idf model significantly outperforms the baseline model with only the computed features, achieving a 76% overally accuracy. It is still struggling with to identify the fake reviews and is identifying far too many of the real reviews as fake, with a relatively abysmal precision of 26% for the fake reviews. This is still an improvement over the other model, with had a precision of only 18%, but there is still significant room for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b102aec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26d283c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aaa',\n",
       " 'aaaa',\n",
       " 'aaaaa',\n",
       " 'aaaaaaaaaaaa',\n",
       " 'aaaaaaaaaaaaaaaaaa',\n",
       " 'aaaaaaaaaaaaaaaasaaaaaaaaaammmmmmmmmmmmmaaaaaaaaaa',\n",
       " 'aaaaaaaaaaaaaand',\n",
       " 'aaaaaaaaaaaaaayo',\n",
       " 'aaaaaaaaaaaaah',\n",
       " 'aaaaaaaaaaaallll',\n",
       " 'aaaaaaaaaaaamazing',\n",
       " 'aaaaaaaaaaamazing',\n",
       " 'aaaaaaaaamazing',\n",
       " 'aaaaaaaaand',\n",
       " 'aaaaaaaahh',\n",
       " 'aaaaaaaammazingggg',\n",
       " 'aaaaaaaand',\n",
       " 'aaaaaaaanyway',\n",
       " 'aaaaaaah',\n",
       " 'aaaaaaamazing',\n",
       " 'aaaaaaamazzzzing',\n",
       " 'aaaaaaand',\n",
       " 'aaaaaaanywhoo',\n",
       " 'aaaaaaay',\n",
       " 'aaaaaach',\n",
       " 'aaaaaah',\n",
       " 'aaaaaahh',\n",
       " 'aaaaaahhhhh',\n",
       " 'aaaaaahhhmada',\n",
       " 'aaaaaamazing',\n",
       " 'aaaaaammaaazzzzingggg',\n",
       " 'aaaaaammmmmaaazing',\n",
       " 'aaaaaammmmmzzzzzzing',\n",
       " 'aaaaaand',\n",
       " 'aaaaaanyway',\n",
       " 'aaaaaargh',\n",
       " 'aaaaaarrrrrggghhhh',\n",
       " 'aaaaah',\n",
       " 'aaaaahhh',\n",
       " 'aaaaahhhh',\n",
       " 'aaaaahhhhh',\n",
       " 'aaaaahhhhmaaaaayyyyziiiiiiing',\n",
       " 'aaaaahhhhmazing',\n",
       " 'aaaaahhhhmazzzing',\n",
       " 'aaaaahmazing',\n",
       " 'aaaaall',\n",
       " 'aaaaalll',\n",
       " 'aaaaallll',\n",
       " 'aaaaamaazzzzing',\n",
       " 'aaaaamahhzing',\n",
       " 'aaaaamaxing',\n",
       " 'aaaaamazing',\n",
       " 'aaaaamazinggg',\n",
       " 'aaaaammmaaazzziiinnnggg',\n",
       " 'aaaaammmmmazing',\n",
       " 'aaaaand',\n",
       " 'aaaaangry',\n",
       " 'aaaaannnd',\n",
       " 'aaaaannnnddddd',\n",
       " 'aaaaannnnnddddask',\n",
       " 'aaaaanyway',\n",
       " 'aaaaawesome',\n",
       " 'aaaaaws',\n",
       " 'aaaaawwwoooooo',\n",
       " 'aaaach',\n",
       " 'aaaadorable',\n",
       " 'aaaages',\n",
       " 'aaaah',\n",
       " 'aaaahahaha',\n",
       " 'aaaahh',\n",
       " 'aaaahhh',\n",
       " 'aaaahhhhh',\n",
       " 'aaaahhhnyonya',\n",
       " 'aaaahing',\n",
       " 'aaaahmazing',\n",
       " 'aaaahthose',\n",
       " 'aaaaight',\n",
       " 'aaaall',\n",
       " 'aaaallll',\n",
       " 'aaaalllllllllll',\n",
       " 'aaaalmost',\n",
       " 'aaaalright',\n",
       " 'aaaalways',\n",
       " 'aaaamaaaaazing',\n",
       " 'aaaamaaaaziiiiingg',\n",
       " 'aaaamaaaazing',\n",
       " 'aaaamaaaazzing',\n",
       " 'aaaamaaaazzzing',\n",
       " 'aaaamazing',\n",
       " 'aaaamazinnng',\n",
       " 'aaaammmaaaazzzing',\n",
       " 'aaaammmmaaazzzing',\n",
       " 'aaaammmmazing',\n",
       " 'aaaand',\n",
       " 'aaaandd',\n",
       " 'aaaannd',\n",
       " 'aaaannndddd',\n",
       " 'aaaannndddwe',\n",
       " 'aaaannnnd',\n",
       " 'aaaannnnddd',\n",
       " 'aaaannnnnnd',\n",
       " 'aaaannnnnnnnnnnnd',\n",
       " 'aaaanyway',\n",
       " 'aaaargh',\n",
       " 'aaaawesome',\n",
       " 'aaaawww',\n",
       " 'aaack',\n",
       " 'aaages',\n",
       " 'aaaggess',\n",
       " 'aaah',\n",
       " 'aaahaa',\n",
       " 'aaahd',\n",
       " 'aaahed',\n",
       " 'aaahh',\n",
       " 'aaahhed',\n",
       " 'aaahhh',\n",
       " 'aaahhha',\n",
       " 'aaahhhh',\n",
       " 'aaahhhhh',\n",
       " 'aaahhhhhh',\n",
       " 'aaahhhhhhhh',\n",
       " 'aaahhhhhmazing',\n",
       " 'aaahhhhi',\n",
       " 'aaahhhhmazzing',\n",
       " 'aaahhhoooouuuuuum',\n",
       " 'aaahhhs',\n",
       " 'aaahhmazing',\n",
       " 'aaahhthe',\n",
       " 'aaahing',\n",
       " 'aaahmazing',\n",
       " 'aaahs',\n",
       " 'aaaieeeeearrgggghhhhhh',\n",
       " 'aaall',\n",
       " 'aaalllll',\n",
       " 'aaallllright',\n",
       " 'aaalways',\n",
       " 'aaamaazzingg',\n",
       " 'aaamazing',\n",
       " 'aaammaaazzzing',\n",
       " 'aaammm',\n",
       " 'aaammmmmmmaaazziinnngggg',\n",
       " 'aaand',\n",
       " 'aaandddd',\n",
       " 'aaandi',\n",
       " 'aaannnd',\n",
       " 'aaannndd',\n",
       " 'aaannnndddd',\n",
       " 'aaannnnddddcheck',\n",
       " 'aaaoookkkkk',\n",
       " 'aaargh',\n",
       " 'aaarrgghh',\n",
       " 'aaauuhhhmaazzzing',\n",
       " 'aaavantage',\n",
       " 'aaawesome',\n",
       " 'aaawhere',\n",
       " 'aaawwwrightbut',\n",
       " 'aaayyyeeee',\n",
       " 'aabsolutely',\n",
       " 'aac',\n",
       " 'aace',\n",
       " 'aachar',\n",
       " 'aachari',\n",
       " 'aadd',\n",
       " 'aadvantage',\n",
       " 'aag',\n",
       " 'aagin',\n",
       " 'aah',\n",
       " 'aahaa',\n",
       " 'aahd',\n",
       " 'aahh',\n",
       " 'aahhh',\n",
       " 'aahhhh',\n",
       " 'aahhhhh',\n",
       " 'aahhhhhhhh',\n",
       " 'aahhhhhing',\n",
       " 'aahhhhmazing',\n",
       " 'aahhhing',\n",
       " 'aahhhmmmaaazzziiiinnngg',\n",
       " 'aahhhwwwwwwwww',\n",
       " 'aahhing',\n",
       " 'aahmazeballs',\n",
       " 'aahnold',\n",
       " 'aaight',\n",
       " 'aail',\n",
       " 'aailability',\n",
       " 'aak',\n",
       " 'aaking',\n",
       " 'aalba',\n",
       " 'aaldkfjalkdfjaldfk',\n",
       " 'aale',\n",
       " 'aaliyah',\n",
       " 'aaliyahs',\n",
       " 'aallllllll',\n",
       " 'aaloo',\n",
       " 'aalright',\n",
       " 'aalu',\n",
       " 'aam',\n",
       " 'aamazing',\n",
       " 'aamerican',\n",
       " 'aammmaaaaaaaazing',\n",
       " 'aamzing',\n",
       " 'aand',\n",
       " 'aandwich',\n",
       " 'aannnd',\n",
       " 'aannnndddd',\n",
       " 'aannnnnnnd',\n",
       " 'aannoyed',\n",
       " 'aanrader',\n",
       " 'aanradertje',\n",
       " 'aanyways',\n",
       " 'aaolutely',\n",
       " 'aap',\n",
       " 'aapam',\n",
       " 'aappam',\n",
       " 'aapprox',\n",
       " 'aaps',\n",
       " 'aaran',\n",
       " 'aardvark',\n",
       " 'aarggh',\n",
       " 'aargh',\n",
       " 'aarmison',\n",
       " 'aaron',\n",
       " 'aaronsilly',\n",
       " 'aaround',\n",
       " 'aarp',\n",
       " 'aarrrrggghhh',\n",
       " 'aaryn',\n",
       " 'aasado',\n",
       " 'aasak',\n",
       " 'aash',\n",
       " 'aashak',\n",
       " 'aashedal',\n",
       " 'aashi',\n",
       " 'aasnt',\n",
       " 'aastha',\n",
       " 'aat',\n",
       " 'aatirachi',\n",
       " 'aatmosphere',\n",
       " 'aattentive',\n",
       " 'aaverage',\n",
       " 'aawesome',\n",
       " 'aawsom',\n",
       " 'aayah',\n",
       " 'aayyyyy',\n",
       " 'aazing',\n",
       " 'ab',\n",
       " 'aba',\n",
       " 'ababa',\n",
       " 'ababsolutely',\n",
       " 'abaca',\n",
       " 'aback',\n",
       " 'abacknot',\n",
       " 'abacuk',\n",
       " 'abacus',\n",
       " 'abad',\n",
       " 'abadia',\n",
       " 'abale',\n",
       " 'abaleh',\n",
       " 'abalehs',\n",
       " 'aballminable',\n",
       " 'abalone',\n",
       " 'abandon',\n",
       " 'abandondened',\n",
       " 'abandoneddock',\n",
       " 'abandonedfor',\n",
       " 'abandonedish',\n",
       " 'abandonedlooking',\n",
       " 'abandonment',\n",
       " 'abar',\n",
       " 'abash',\n",
       " 'abashedly',\n",
       " 'abate',\n",
       " 'abatement',\n",
       " 'abatesabsolutely',\n",
       " 'abatespersonally',\n",
       " 'abattoir',\n",
       " 'abb',\n",
       " 'abba',\n",
       " 'abbacchio',\n",
       " 'abbachio',\n",
       " 'abbas',\n",
       " 'abbatoir',\n",
       " 'abbaye',\n",
       " 'abbayegood',\n",
       " 'abbayes',\n",
       " 'abbazabba',\n",
       " 'abbbbbsolutely',\n",
       " 'abberation',\n",
       " 'abbey',\n",
       " 'abbeye',\n",
       " 'abbiamo',\n",
       " 'abbie',\n",
       " 'abbinamenti',\n",
       " 'abbondante',\n",
       " 'abbondanza',\n",
       " 'abbordabili',\n",
       " 'abbot',\n",
       " 'abbott',\n",
       " 'abbotts',\n",
       " 'abbounds',\n",
       " 'abbout',\n",
       " 'abbracci',\n",
       " 'abbracciamentos',\n",
       " 'abbraccio',\n",
       " 'abbracio',\n",
       " 'abbrasive',\n",
       " 'abbreviate',\n",
       " 'abbreviation',\n",
       " 'abbruzzi',\n",
       " 'abbuffata',\n",
       " 'abby',\n",
       " 'abbye',\n",
       " 'abbys',\n",
       " 'abbysynias',\n",
       " 'abc',\n",
       " 'abcchendol',\n",
       " 'abcd',\n",
       " 'abcde',\n",
       " 'abcdef',\n",
       " 'abcdefn',\n",
       " 'abceats',\n",
       " 'abcfarm',\n",
       " 'abcits',\n",
       " 'abck',\n",
       " 'abckitchen',\n",
       " 'abckitchennyccom',\n",
       " 'abcks',\n",
       " 'abcmandarin',\n",
       " 'abcmy',\n",
       " 'abcnewsgocomnightline',\n",
       " 'abcrunchy',\n",
       " 'abcyou',\n",
       " 'abd',\n",
       " 'abdicate',\n",
       " 'abdomen',\n",
       " 'abdominal',\n",
       " 'abds',\n",
       " 'abduct',\n",
       " 'abduction',\n",
       " 'abductionan',\n",
       " 'abductor',\n",
       " 'abdul',\n",
       " 'abduljabar',\n",
       " 'abduls',\n",
       " 'abdunace',\n",
       " 'abdunance',\n",
       " 'abe',\n",
       " 'abed',\n",
       " 'abeets',\n",
       " 'abeetz',\n",
       " 'abeetza',\n",
       " 'abeez',\n",
       " 'abeiile',\n",
       " 'abeille',\n",
       " 'abeilleeverything',\n",
       " 'abeilles',\n",
       " 'abeilleso',\n",
       " 'abeillie',\n",
       " 'abeit',\n",
       " 'abel',\n",
       " 'abendstunden',\n",
       " 'aber',\n",
       " 'aberage',\n",
       " 'abercombie',\n",
       " 'abercrombie',\n",
       " 'abercrombiehollister',\n",
       " 'abercrombietype',\n",
       " 'aberdeen',\n",
       " 'aberdonian',\n",
       " 'aberline',\n",
       " 'aberlour',\n",
       " 'aberrant',\n",
       " 'aberration',\n",
       " 'aberrational',\n",
       " 'abes',\n",
       " 'abesolutely',\n",
       " 'abet',\n",
       " 'abetter',\n",
       " 'abeulo',\n",
       " 'abeyance',\n",
       " 'abfab',\n",
       " 'abgelehnt',\n",
       " 'abgelos',\n",
       " 'abhay',\n",
       " 'abhinav',\n",
       " 'abhiruchi',\n",
       " 'abhishek',\n",
       " 'abhor',\n",
       " 'abhorrence',\n",
       " 'abhorrent',\n",
       " 'abhorrently',\n",
       " 'abi',\n",
       " 'abiance',\n",
       " 'abichuelas',\n",
       " 'abichula',\n",
       " 'abid',\n",
       " 'abidance',\n",
       " 'abide',\n",
       " 'abielle',\n",
       " 'abience',\n",
       " 'abient',\n",
       " 'abierta',\n",
       " 'abig',\n",
       " 'abigail',\n",
       " 'abigails',\n",
       " 'abigtastymealforfourdollars',\n",
       " 'abilene',\n",
       " 'ability',\n",
       " 'abilitymanpower',\n",
       " 'abillities',\n",
       " 'abilone',\n",
       " 'abilty',\n",
       " 'abindanza',\n",
       " 'abingdon',\n",
       " 'abington',\n",
       " 'abirthday',\n",
       " 'abiruchi',\n",
       " 'abish',\n",
       " 'abismal',\n",
       " 'abismalthe',\n",
       " 'abistro',\n",
       " 'abit',\n",
       " 'abita',\n",
       " 'abitaour',\n",
       " 'abitas',\n",
       " 'abitha',\n",
       " 'abitinos',\n",
       " 'abito',\n",
       " 'abitonthedryside',\n",
       " 'abitworsethandecent',\n",
       " 'abizz',\n",
       " 'abject',\n",
       " 'abjectly',\n",
       " 'abjure',\n",
       " 'ablate',\n",
       " 'ablaze',\n",
       " 'ablazeit',\n",
       " 'ablazin',\n",
       " 'able',\n",
       " 'ablebodied',\n",
       " 'ableg',\n",
       " 'ableit',\n",
       " 'ableminded',\n",
       " 'ables',\n",
       " 'abliged',\n",
       " 'abligingly',\n",
       " 'abliguration',\n",
       " 'ablondigas',\n",
       " 'ablt',\n",
       " 'ably',\n",
       " 'abmiance',\n",
       " 'abnd',\n",
       " 'abner',\n",
       " 'abners',\n",
       " 'abnocious',\n",
       " 'abnormal',\n",
       " 'abnormality',\n",
       " 'abnormally',\n",
       " 'abnoxious',\n",
       " 'aboard',\n",
       " 'abobada',\n",
       " 'abobrinha',\n",
       " 'abodaba',\n",
       " 'abodabo',\n",
       " 'abodanza',\n",
       " 'abode',\n",
       " 'abodo',\n",
       " 'abogados',\n",
       " 'abojt',\n",
       " 'abol',\n",
       " 'abolish',\n",
       " 'abolition',\n",
       " 'abolitionistapproachcom',\n",
       " 'abolone',\n",
       " 'abolsutely',\n",
       " 'abolutely',\n",
       " 'abomasum',\n",
       " 'abominability',\n",
       " 'abominable',\n",
       " 'abominably',\n",
       " 'abominate',\n",
       " 'abomination',\n",
       " 'abondanza',\n",
       " 'abondigas',\n",
       " 'aboomin',\n",
       " 'aboooooooo',\n",
       " 'aboot',\n",
       " 'aboout',\n",
       " 'aboput',\n",
       " 'abordableabordable',\n",
       " 'aboriginal',\n",
       " 'aborio',\n",
       " 'abort',\n",
       " 'abortion',\n",
       " 'abortionist',\n",
       " 'abortive',\n",
       " 'aboslute',\n",
       " 'aboslutely',\n",
       " 'abosolutely',\n",
       " 'abosolutley',\n",
       " 'abosoulty',\n",
       " 'abosultely',\n",
       " 'abot',\n",
       " 'abotu',\n",
       " 'abotut',\n",
       " 'abou',\n",
       " 'abound',\n",
       " 'aboundant',\n",
       " 'aboundedhowever',\n",
       " 'aboundi',\n",
       " 'abour',\n",
       " 'abouta',\n",
       " 'aboutabsolutely',\n",
       " 'aboutactually',\n",
       " 'aboutalas',\n",
       " 'aboutalthough',\n",
       " 'aboutalways',\n",
       " 'aboutand',\n",
       " 'aboutas',\n",
       " 'aboutasked',\n",
       " 'aboutat',\n",
       " 'aboutaverage',\n",
       " 'aboutbartaco',\n",
       " 'aboutbasically',\n",
       " 'aboutbland',\n",
       " 'aboutbut',\n",
       " 'aboutcom',\n",
       " 'aboutcooked',\n",
       " 'aboutcraving',\n",
       " 'aboutdidnt',\n",
       " 'aboutdont',\n",
       " 'abouteven',\n",
       " 'aboutevery',\n",
       " 'aboutexcept',\n",
       " 'aboutface',\n",
       " 'aboutfaced',\n",
       " 'aboutfantastic',\n",
       " 'aboutfood',\n",
       " 'aboutfor',\n",
       " 'aboutforgetaboutit',\n",
       " 'aboutforgo',\n",
       " 'aboutgod',\n",
       " 'aboutgood',\n",
       " 'aboutguess',\n",
       " 'abouth',\n",
       " 'abouthands',\n",
       " 'abouthas',\n",
       " 'abouthuge',\n",
       " 'abouti',\n",
       " 'aboutif',\n",
       " 'aboutill',\n",
       " 'aboutim',\n",
       " 'aboutin',\n",
       " 'aboutindian',\n",
       " 'aboutis',\n",
       " 'aboutit',\n",
       " 'aboutits',\n",
       " 'aboutjob',\n",
       " 'aboutjust',\n",
       " 'aboutlike',\n",
       " 'aboutmatter',\n",
       " 'aboutmay',\n",
       " 'aboutmaybe',\n",
       " 'aboutme',\n",
       " 'aboutmediocre',\n",
       " 'aboutmilky',\n",
       " 'aboutmin',\n",
       " 'aboutmine',\n",
       " 'aboutmuch',\n",
       " 'aboutmy',\n",
       " 'aboutno',\n",
       " 'aboutnone',\n",
       " 'aboutnot',\n",
       " 'aboutnow',\n",
       " 'aboutny',\n",
       " 'abouto',\n",
       " 'aboutold',\n",
       " 'aboutonce',\n",
       " 'aboutone',\n",
       " 'aboutopted',\n",
       " 'aboutor',\n",
       " 'aboutoverall',\n",
       " 'aboutoverpriced',\n",
       " 'aboutpassed',\n",
       " 'aboutperhaps',\n",
       " 'aboutperilla',\n",
       " 'aboutpies',\n",
       " 'aboutplanningscheming',\n",
       " 'aboutpossibly',\n",
       " 'aboutprobably',\n",
       " 'aboutread',\n",
       " 'aboutrealizing',\n",
       " 'aboutreminds',\n",
       " 'abouts',\n",
       " 'aboutsame',\n",
       " 'aboutseen',\n",
       " 'aboutsgreat',\n",
       " 'aboutshe',\n",
       " 'aboutskip',\n",
       " 'aboutso',\n",
       " 'aboutspicy',\n",
       " 'aboutstill',\n",
       " 'aboutthat',\n",
       " 'aboutthe',\n",
       " 'aboutthefoodonly',\n",
       " 'aboutthey',\n",
       " 'abouttheyre',\n",
       " 'aboutthis',\n",
       " 'aboutthought',\n",
       " 'aboutto',\n",
       " 'abouttoasty',\n",
       " 'abouttobe',\n",
       " 'abouttobevacant',\n",
       " 'abouttoburst',\n",
       " 'abouttold',\n",
       " 'abouttoo',\n",
       " 'abouttospoil',\n",
       " 'aboutum',\n",
       " 'aboutunless',\n",
       " 'aboutvery',\n",
       " 'aboutwait',\n",
       " 'aboutwaitoh',\n",
       " 'aboutwas',\n",
       " 'aboutway',\n",
       " 'aboutwe',\n",
       " 'aboutwell',\n",
       " 'aboutwhich',\n",
       " 'aboutwith',\n",
       " 'aboutwowwowby',\n",
       " 'aboutwrong',\n",
       " 'aboutwtf',\n",
       " 'aboutx',\n",
       " 'aboutyou',\n",
       " 'aboutyoure',\n",
       " 'abouy',\n",
       " 'above',\n",
       " 'aboveand',\n",
       " 'aboveandbeyond',\n",
       " 'aboveattention',\n",
       " 'aboveaverage',\n",
       " 'aboveaveragelooking',\n",
       " 'aboveavg',\n",
       " 'abovebelow',\n",
       " 'abovedishes',\n",
       " 'aboveground',\n",
       " 'abovehell',\n",
       " 'abovei',\n",
       " 'aboveits',\n",
       " 'abovelets',\n",
       " 'abovementioned',\n",
       " 'abovemore',\n",
       " 'abovenever',\n",
       " 'abovepar',\n",
       " 'abovepars',\n",
       " 'abovereferenced',\n",
       " 'abovestandard',\n",
       " 'abovethe',\n",
       " 'abovethelawcom',\n",
       " 'abovethought',\n",
       " 'abovetoo',\n",
       " 'abovewell',\n",
       " 'aboveyoure',\n",
       " 'aboveyummers',\n",
       " 'aboyut',\n",
       " 'abp',\n",
       " 'abpastry',\n",
       " 'abput',\n",
       " 'abpve',\n",
       " 'abq',\n",
       " 'abracadabra',\n",
       " 'abraccio',\n",
       " 'abraccios',\n",
       " 'abraco',\n",
       " 'abrade',\n",
       " 'abraham',\n",
       " 'abrahami',\n",
       " 'abrams',\n",
       " 'abrantes',\n",
       " 'abrasion',\n",
       " 'abrasive',\n",
       " 'abrasivebut',\n",
       " 'abrasively',\n",
       " 'abrasiveness',\n",
       " 'abraxxas',\n",
       " 'abraxxxas',\n",
       " 'abrazo',\n",
       " 'abrazos',\n",
       " 'abraço',\n",
       " 'abre',\n",
       " 'abreast',\n",
       " 'abreu',\n",
       " 'abreus',\n",
       " 'abrewin',\n",
       " 'abrhiru',\n",
       " 'abridge',\n",
       " 'abrisket',\n",
       " 'abrit',\n",
       " 'abroad',\n",
       " 'abroadbutcher',\n",
       " 'abroadsuper',\n",
       " 'abrobrina',\n",
       " 'abrubt',\n",
       " 'abrubtly',\n",
       " 'abruiya',\n",
       " 'abrultly',\n",
       " 'abrupt',\n",
       " 'abruptas',\n",
       " 'abruptly',\n",
       " 'abruptness',\n",
       " 'abruptrude',\n",
       " 'abrutzo',\n",
       " 'abruzze',\n",
       " 'abruzzese',\n",
       " 'abruzzesestyle',\n",
       " 'abruzzesi',\n",
       " 'abruzzesse',\n",
       " 'abruzzi',\n",
       " 'abruzzo',\n",
       " 'absabmiller',\n",
       " 'absafruitly',\n",
       " 'absandwich',\n",
       " 'abscense',\n",
       " 'abscent',\n",
       " 'abscond',\n",
       " 'absecon',\n",
       " 'abselutely',\n",
       " 'absence',\n",
       " 'absensce',\n",
       " 'absense',\n",
       " 'absent',\n",
       " 'absentee',\n",
       " 'absenteeism',\n",
       " 'absentia',\n",
       " 'absentminded',\n",
       " 'absentmindedly',\n",
       " 'absentmindely',\n",
       " 'absentservice',\n",
       " 'absentthe',\n",
       " 'absinth',\n",
       " 'absinthe',\n",
       " 'absinthebut',\n",
       " 'absinthechocolatepine',\n",
       " 'absintheenhanced',\n",
       " 'absintheinfused',\n",
       " 'absinthekissed',\n",
       " 'absintherinsed',\n",
       " 'absintherinsedryeandsugarcubecocktail',\n",
       " 'absinthetea',\n",
       " 'absinthey',\n",
       " 'absloutely',\n",
       " 'abso',\n",
       " 'absoawesome',\n",
       " 'absoblutely',\n",
       " 'absoeffinglutely',\n",
       " 'absoeffinlutely',\n",
       " 'absofantastic',\n",
       " 'absofantastically',\n",
       " 'absofinglutely',\n",
       " 'absofreakinglutely',\n",
       " 'absofreakinglutley',\n",
       " 'absofreakinlutely',\n",
       " 'absofreakinlutly',\n",
       " 'absofregginlutely',\n",
       " 'absofrigginloutely',\n",
       " 'absofrigginlutely',\n",
       " 'absofrikkinlutely',\n",
       " 'absofruitly',\n",
       " 'absofuckinglutely',\n",
       " 'absofuckinglutly',\n",
       " 'absofukinloutely',\n",
       " 'absolately',\n",
       " 'absoletely',\n",
       " 'absoljtly',\n",
       " 'absoloutely',\n",
       " 'absoloutly',\n",
       " 'absoltely',\n",
       " 'absoltuely',\n",
       " 'absoluetly',\n",
       " 'absolufreakinlutely',\n",
       " 'absoluletly',\n",
       " 'absolument',\n",
       " 'absolut',\n",
       " 'absolutamente',\n",
       " 'absolute',\n",
       " 'absoluteeeeeee',\n",
       " 'absoluteessentialswordp',\n",
       " 'absolutel',\n",
       " 'absoluteley',\n",
       " 'absolutelly',\n",
       " 'absolutelty',\n",
       " 'absolutely',\n",
       " 'absolutelyand',\n",
       " 'absolutelybest',\n",
       " 'absolutelycouldntbemoreperfectly',\n",
       " 'absolutelydelicious',\n",
       " 'absolutelymusthave',\n",
       " 'absolutelynofrilleatery',\n",
       " 'absolutelypart',\n",
       " 'absolutelyterrible',\n",
       " 'absolutelythinking',\n",
       " 'absolutelyyyy',\n",
       " 'absolutement',\n",
       " 'absolutemust',\n",
       " 'absolutetly',\n",
       " 'absolutety',\n",
       " 'absolutey',\n",
       " 'absolution',\n",
       " 'absolutist',\n",
       " 'absolutlely',\n",
       " 'absolutley',\n",
       " 'absolutly',\n",
       " 'absolututely',\n",
       " 'absoluuuutely',\n",
       " 'absoluuuuuuutely',\n",
       " 'absolve',\n",
       " 'absooluuutly',\n",
       " 'absooolutellyyyyyy',\n",
       " 'absoooolutely',\n",
       " 'absorb',\n",
       " 'absorbance',\n",
       " 'absorbant',\n",
       " 'absorbe',\n",
       " 'absorbency',\n",
       " 'absorbent',\n",
       " 'absorbentcant',\n",
       " 'absorbently',\n",
       " 'absorber',\n",
       " 'absorption',\n",
       " 'absorutely',\n",
       " 'absoulely',\n",
       " 'absouletly',\n",
       " 'absoulety',\n",
       " 'absoulte',\n",
       " 'absoultely',\n",
       " 'absoultley',\n",
       " 'absoulty',\n",
       " 'absoulutely',\n",
       " 'absoulutley',\n",
       " 'absoute',\n",
       " 'absoutely',\n",
       " 'absoutley',\n",
       " 'absoyou',\n",
       " 'abstain',\n",
       " 'abstainer',\n",
       " 'abstinence',\n",
       " 'abstinent',\n",
       " 'abstract',\n",
       " 'abstractformed',\n",
       " 'abstraction',\n",
       " 'abstractly',\n",
       " 'abstractminded',\n",
       " 'abstruse',\n",
       " 'absulotly',\n",
       " 'absurb',\n",
       " 'absurd',\n",
       " 'absurdare',\n",
       " 'absurdely',\n",
       " 'absurdity',\n",
       " 'absurditylike',\n",
       " 'absurdly',\n",
       " 'absurdlyreasonablypriced',\n",
       " 'absurdthey',\n",
       " 'absurdum',\n",
       " 'absurdyou',\n",
       " 'absutely',\n",
       " 'absynnia',\n",
       " 'absynth',\n",
       " 'absynthe',\n",
       " 'abt',\n",
       " 'abte',\n",
       " 'abtw',\n",
       " 'abu',\n",
       " 'abubblin',\n",
       " 'abuckashuck',\n",
       " 'abudant',\n",
       " 'abudnant',\n",
       " 'abudundent',\n",
       " 'abuela',\n",
       " 'abuelagrindingcorninthekitchenauthentic',\n",
       " 'abuelas',\n",
       " 'abuelita',\n",
       " 'abuelitas',\n",
       " 'abuelitos',\n",
       " 'abuelo',\n",
       " 'abuelos',\n",
       " 'abujamal',\n",
       " 'abul',\n",
       " 'abunch',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'abundantalso',\n",
       " 'abundantand',\n",
       " 'abundante',\n",
       " 'abundantly',\n",
       " 'abundent',\n",
       " 'abundio',\n",
       " 'abuot',\n",
       " 'abura',\n",
       " 'aburaage',\n",
       " 'aburasoba',\n",
       " 'aburger',\n",
       " 'aburi',\n",
       " 'aburiya',\n",
       " 'aburiyaki',\n",
       " 'aburiye',\n",
       " 'aburrida',\n",
       " 'abus',\n",
       " 'abuse',\n",
       " 'abuseat',\n",
       " 'abusebigotry',\n",
       " 'abuser',\n",
       " 'abusewearing',\n",
       " 'abusive',\n",
       " 'abusively',\n",
       " 'abuso',\n",
       " 'abustle',\n",
       " 'abut',\n",
       " 'abutter',\n",
       " 'abutts',\n",
       " 'abuzz',\n",
       " 'abuzzing',\n",
       " 'abuzzkill',\n",
       " 'abv',\n",
       " 'abviously',\n",
       " 'abvoe',\n",
       " 'abvs',\n",
       " 'aby',\n",
       " 'abysinnian',\n",
       " 'abysmal',\n",
       " 'abysmaldemerit',\n",
       " 'abysmally',\n",
       " 'abysmallylong',\n",
       " 'abysmalsurly',\n",
       " 'abysmalthe',\n",
       " 'abyssal',\n",
       " 'abysscreature',\n",
       " 'abyssinia',\n",
       " 'abyssinian',\n",
       " 'abyssmal',\n",
       " 'abyssmally',\n",
       " 'abythig',\n",
       " 'ac',\n",
       " 'aca',\n",
       " 'acaba',\n",
       " 'acabado',\n",
       " 'acabamos',\n",
       " 'acacia',\n",
       " 'acacian',\n",
       " 'academia',\n",
       " 'academic',\n",
       " 'academicbookish',\n",
       " 'academy',\n",
       " 'acadia',\n",
       " 'acadian',\n",
       " 'acadiana',\n",
       " 'acafe',\n",
       " 'acai',\n",
       " 'acaii',\n",
       " 'acaipirinha',\n",
       " 'acallin',\n",
       " 'acamuramodern',\n",
       " 'acan',\n",
       " 'acand',\n",
       " 'acapella',\n",
       " 'acapellos',\n",
       " 'acapluco',\n",
       " 'acapolco',\n",
       " 'acappello',\n",
       " 'acapulco',\n",
       " 'acapurias',\n",
       " 'acaraje',\n",
       " 'acarajé',\n",
       " 'acarajés',\n",
       " 'acarnivore',\n",
       " 'acb',\n",
       " 'acc',\n",
       " 'accanto',\n",
       " 'accapurea',\n",
       " 'accardi',\n",
       " 'accceptable',\n",
       " 'acccommodated',\n",
       " 'acccomodated',\n",
       " 'acccomodating',\n",
       " 'acccompanied',\n",
       " 'acccompany',\n",
       " 'accdg',\n",
       " 'accecibles',\n",
       " 'accede',\n",
       " 'accel',\n",
       " 'accelerate',\n",
       " 'acceleration',\n",
       " 'accent',\n",
       " 'accentally',\n",
       " 'accentand',\n",
       " 'accentannoyed',\n",
       " 'accentbless',\n",
       " 'accentehh',\n",
       " 'accentfree',\n",
       " 'accenthe']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting some of the lemmatized words, I see a few that appear to be errors in preprocessing\n",
    "sorted(vectorizer.get_feature_names_out()[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5605e109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"Don Peppe's is old school Italian at it's best....Go in...mind your business...order the meal...and don't rat on your friends. And if you get \\xa0pinched, tell them nothing!!!....Seriously, the baked clams, linguine white clam, shrimp Luciano over linguine and veal don peppe is what's it's all about....Forgetaboutit!!!!\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Error in the preprocessing, concatenating words together that are separated by ... and possibly other character/cases as well\n",
    "preprocessed_data[preprocessed_data.lemmatized_word_list.str.lower().str.contains('aboutforgetaboutit')].full_review.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a612b953",
   "metadata": {},
   "source": [
    "Potentially interesting feature I thought of after seeing these error cases, analyzing the usage of punctuation in the sentence. We usually strip all this information out when doing the preprocessing, but maybe it would be interesting to include counts of different types of punctuation? (!.,? are the main ones that jump to mind) Not sure how predictive this is of fake/authentic reviews but perhaps it's useful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a34ce1",
   "metadata": {},
   "source": [
    "The TF-IDF model is moving in the right direction, but it is still struggling to properly identify the fake reviews. Let's try a slightly more complex representation, using bi-grams instead of uni-grams, and see if this helps with picking out the fake reviews. We can also try alternatives where we combine the summary features from the original model into the TF-IDF model and see if that helps as well, since there did seem to be some important information that those features were capturing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aecf312b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(ngram_range=(2, 2))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(ngram_range=(2, 2))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(ngram_range=(2, 2))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF vectorizer with bigram only representation\n",
    "vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(2,2))\n",
    "vectorizer.fit(preprocessed_data.lemmatized_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b338ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426018, 6357944)\n",
      "(182580, 6357944)\n",
      "CPU times: total: 1min 7s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tfidf2_svm = LinearSVC()\n",
    "\n",
    "# Using imblearn pipeline to manage the scaling and resampling logic in a simple way\n",
    "tfidf2_svm_pipe = Pipeline([('upsampler', resampler),\n",
    "                            ('svc', tfidf2_svm)])\n",
    "\n",
    "tfidf2_x_train = vectorizer.transform(X_train)\n",
    "tfidf2_x_test = vectorizer.transform(X_test)\n",
    "\n",
    "print(tfidf2_x_train.shape)\n",
    "print(tfidf2_x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7253e50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 31s\n",
      "Wall time: 1min 32s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;upsampler&#x27;, SMOTE(k_neighbors=3, random_state=24)),\n",
       "                (&#x27;svc&#x27;, LinearSVC())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;upsampler&#x27;, SMOTE(k_neighbors=3, random_state=24)),\n",
       "                (&#x27;svc&#x27;, LinearSVC())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE(k_neighbors=3, random_state=24)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('upsampler', SMOTE(k_neighbors=3, random_state=24)),\n",
       "                ('svc', LinearSVC())])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tfidf2_svm_pipe.fit(tfidf2_x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e748f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.25      0.34      0.29     24295\n",
      "           1       0.89      0.84      0.87    158285\n",
      "\n",
      "    accuracy                           0.78    182580\n",
      "   macro avg       0.57      0.59      0.58    182580\n",
      "weighted avg       0.81      0.78      0.79    182580\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  8177,  16118],\n",
       "       [ 24863, 133422]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf2_preds = tfidf2_svm_pipe.predict(tfidf2_x_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, tfidf2_preds))\n",
    "metrics.confusion_matrix(y_test, tfidf2_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dde27c",
   "metadata": {},
   "source": [
    "The bi-gram representation is significantly more complex (6,356,944 input features vs 323,907 features in the uni-gram), and unfortunately this additional complexity does not appear to be helping the model performance. Accuracy has slightly increased on our test set but both the precision and recall have decreased, and the overall number of fake reviews correctly identified has also decreased. More than likely we are running into issues with the representation being too complex for the amount of training data that we have when using bi-grams, so it would seem to make more sense to use the uni-gram representation and try to iterate on this to find a better model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7b95f3",
   "metadata": {},
   "source": [
    "Next, let's try to incorporate the original summary features into the uni-gram TF-IDF model and see if those features help at all with the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b5fdb5e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426018, 9)\n",
      "(182580, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;summary&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;num_words&#x27;, &#x27;num_verbs&#x27;,\n",
       "                                                   &#x27;avg_word_len&#x27;,\n",
       "                                                   &#x27;emotiveness_ratio&#x27;,\n",
       "                                                   &#x27;num_positive_words&#x27;,\n",
       "                                                   &#x27;num_negative_words&#x27;,\n",
       "                                                   &#x27;sentiment&#x27;, &#x27;rating&#x27;]),\n",
       "                                                 (&#x27;tfidf&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
       "                                                                   TfidfVectorizer())]),\n",
       "                                                  &#x27;lemmatized_word_list&#x27;)])),\n",
       "                (&#x27;upsampler&#x27;, SMOTE(k_neighbors=3, random_state=24)),\n",
       "                (&#x27;svc&#x27;, LinearSVC())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-43\" type=\"checkbox\" ><label for=\"sk-estimator-id-43\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;summary&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;num_words&#x27;, &#x27;num_verbs&#x27;,\n",
       "                                                   &#x27;avg_word_len&#x27;,\n",
       "                                                   &#x27;emotiveness_ratio&#x27;,\n",
       "                                                   &#x27;num_positive_words&#x27;,\n",
       "                                                   &#x27;num_negative_words&#x27;,\n",
       "                                                   &#x27;sentiment&#x27;, &#x27;rating&#x27;]),\n",
       "                                                 (&#x27;tfidf&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
       "                                                                   TfidfVectorizer())]),\n",
       "                                                  &#x27;lemmatized_word_list&#x27;)])),\n",
       "                (&#x27;upsampler&#x27;, SMOTE(k_neighbors=3, random_state=24)),\n",
       "                (&#x27;svc&#x27;, LinearSVC())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-44\" type=\"checkbox\" ><label for=\"sk-estimator-id-44\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessing: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;summary&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;num_words&#x27;, &#x27;num_verbs&#x27;, &#x27;avg_word_len&#x27;,\n",
       "                                  &#x27;emotiveness_ratio&#x27;, &#x27;num_positive_words&#x27;,\n",
       "                                  &#x27;num_negative_words&#x27;, &#x27;sentiment&#x27;,\n",
       "                                  &#x27;rating&#x27;]),\n",
       "                                (&#x27;tfidf&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
       "                                                  TfidfVectorizer())]),\n",
       "                                 &#x27;lemmatized_word_list&#x27;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-45\" type=\"checkbox\" ><label for=\"sk-estimator-id-45\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">summary</label><div class=\"sk-toggleable__content\"><pre>[&#x27;num_words&#x27;, &#x27;num_verbs&#x27;, &#x27;avg_word_len&#x27;, &#x27;emotiveness_ratio&#x27;, &#x27;num_positive_words&#x27;, &#x27;num_negative_words&#x27;, &#x27;sentiment&#x27;, &#x27;rating&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-46\" type=\"checkbox\" ><label for=\"sk-estimator-id-46\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-47\" type=\"checkbox\" ><label for=\"sk-estimator-id-47\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">tfidf</label><div class=\"sk-toggleable__content\"><pre>lemmatized_word_list</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-48\" type=\"checkbox\" ><label for=\"sk-estimator-id-48\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-49\" type=\"checkbox\" ><label for=\"sk-estimator-id-49\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE(k_neighbors=3, random_state=24)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-50\" type=\"checkbox\" ><label for=\"sk-estimator-id-50\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 ColumnTransformer(transformers=[('summary',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['num_words', 'num_verbs',\n",
       "                                                   'avg_word_len',\n",
       "                                                   'emotiveness_ratio',\n",
       "                                                   'num_positive_words',\n",
       "                                                   'num_negative_words',\n",
       "                                                   'sentiment', 'rating']),\n",
       "                                                 ('tfidf',\n",
       "                                                  Pipeline(steps=[('vectorizer',\n",
       "                                                                   TfidfVectorizer())]),\n",
       "                                                  'lemmatized_word_list')])),\n",
       "                ('upsampler', SMOTE(k_neighbors=3, random_state=24)),\n",
       "                ('svc', LinearSVC())])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "tfidf_combined_svm = LinearSVC()\n",
    "X_train, X_test, y_train, y_test = train_test_split(preprocessed_data[filtered_features + ['lemmatized_word_list']],\n",
    "                                                    preprocessed_data[label_col].values,\n",
    "                                                    test_size=.3,\n",
    "                                                    random_state=24)\n",
    "\n",
    "summary_pipeline = Pipeline([('scaler', StandardScaler())])\n",
    "tfidf_pipeline = Pipeline([('vectorizer', TfidfVectorizer(analyzer='word', ngram_range=(1,1)))])\n",
    "column_processor = ColumnTransformer([('summary', summary_pipeline, filtered_features),\n",
    "                                      ('tfidf', tfidf_pipeline, 'lemmatized_word_list')])\n",
    "\n",
    "\n",
    "tfidf_combined_svm_pipe = Pipeline([('preprocessing', column_processor),\n",
    "                                    ('upsampler', resampler),\n",
    "                                    ('svc', tfidf_combined_svm)])\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "tfidf_combined_svm_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "87a60acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 10min 48s\n",
      "Wall time: 10min 53s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Data_Science_Studies\\GTech\\.venv\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-14 {color: black;background-color: white;}#sk-container-id-14 pre{padding: 0;}#sk-container-id-14 div.sk-toggleable {background-color: white;}#sk-container-id-14 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-14 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-14 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-14 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-14 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-14 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-14 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-14 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-14 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-14 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-14 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-14 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-14 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-14 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-14 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-14 div.sk-item {position: relative;z-index: 1;}#sk-container-id-14 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-14 div.sk-item::before, #sk-container-id-14 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-14 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-14 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-14 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-14 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-14 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-14 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-14 div.sk-label-container {text-align: center;}#sk-container-id-14 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-14 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-14\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;summary&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;num_words&#x27;, &#x27;num_verbs&#x27;,\n",
       "                                                   &#x27;avg_word_len&#x27;,\n",
       "                                                   &#x27;emotiveness_ratio&#x27;,\n",
       "                                                   &#x27;num_positive_words&#x27;,\n",
       "                                                   &#x27;num_negative_words&#x27;,\n",
       "                                                   &#x27;sentiment&#x27;, &#x27;rating&#x27;]),\n",
       "                                                 (&#x27;tfidf&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
       "                                                                   TfidfVectorizer())]),\n",
       "                                                  &#x27;lemmatized_word_list&#x27;)])),\n",
       "                (&#x27;upsampler&#x27;, SMOTE(k_neighbors=3, random_state=24)),\n",
       "                (&#x27;svc&#x27;, LinearSVC())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-51\" type=\"checkbox\" ><label for=\"sk-estimator-id-51\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessing&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;summary&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;num_words&#x27;, &#x27;num_verbs&#x27;,\n",
       "                                                   &#x27;avg_word_len&#x27;,\n",
       "                                                   &#x27;emotiveness_ratio&#x27;,\n",
       "                                                   &#x27;num_positive_words&#x27;,\n",
       "                                                   &#x27;num_negative_words&#x27;,\n",
       "                                                   &#x27;sentiment&#x27;, &#x27;rating&#x27;]),\n",
       "                                                 (&#x27;tfidf&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
       "                                                                   TfidfVectorizer())]),\n",
       "                                                  &#x27;lemmatized_word_list&#x27;)])),\n",
       "                (&#x27;upsampler&#x27;, SMOTE(k_neighbors=3, random_state=24)),\n",
       "                (&#x27;svc&#x27;, LinearSVC())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-52\" type=\"checkbox\" ><label for=\"sk-estimator-id-52\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessing: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;summary&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;num_words&#x27;, &#x27;num_verbs&#x27;, &#x27;avg_word_len&#x27;,\n",
       "                                  &#x27;emotiveness_ratio&#x27;, &#x27;num_positive_words&#x27;,\n",
       "                                  &#x27;num_negative_words&#x27;, &#x27;sentiment&#x27;,\n",
       "                                  &#x27;rating&#x27;]),\n",
       "                                (&#x27;tfidf&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;vectorizer&#x27;,\n",
       "                                                  TfidfVectorizer())]),\n",
       "                                 &#x27;lemmatized_word_list&#x27;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-53\" type=\"checkbox\" ><label for=\"sk-estimator-id-53\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">summary</label><div class=\"sk-toggleable__content\"><pre>[&#x27;num_words&#x27;, &#x27;num_verbs&#x27;, &#x27;avg_word_len&#x27;, &#x27;emotiveness_ratio&#x27;, &#x27;num_positive_words&#x27;, &#x27;num_negative_words&#x27;, &#x27;sentiment&#x27;, &#x27;rating&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-54\" type=\"checkbox\" ><label for=\"sk-estimator-id-54\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-55\" type=\"checkbox\" ><label for=\"sk-estimator-id-55\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">tfidf</label><div class=\"sk-toggleable__content\"><pre>lemmatized_word_list</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-56\" type=\"checkbox\" ><label for=\"sk-estimator-id-56\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-57\" type=\"checkbox\" ><label for=\"sk-estimator-id-57\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE(k_neighbors=3, random_state=24)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-58\" type=\"checkbox\" ><label for=\"sk-estimator-id-58\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessing',\n",
       "                 ColumnTransformer(transformers=[('summary',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['num_words', 'num_verbs',\n",
       "                                                   'avg_word_len',\n",
       "                                                   'emotiveness_ratio',\n",
       "                                                   'num_positive_words',\n",
       "                                                   'num_negative_words',\n",
       "                                                   'sentiment', 'rating']),\n",
       "                                                 ('tfidf',\n",
       "                                                  Pipeline(steps=[('vectorizer',\n",
       "                                                                   TfidfVectorizer())]),\n",
       "                                                  'lemmatized_word_list')])),\n",
       "                ('upsampler', SMOTE(k_neighbors=3, random_state=24)),\n",
       "                ('svc', LinearSVC())])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tfidf_combined_svm_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "81c172ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.25      0.54      0.34     24295\n",
      "           1       0.91      0.75      0.82    158285\n",
      "\n",
      "    accuracy                           0.72    182580\n",
      "   macro avg       0.58      0.64      0.58    182580\n",
      "weighted avg       0.82      0.72      0.76    182580\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 13076,  11219],\n",
       "       [ 39714, 118571]], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_combined_preds = tfidf_combined_svm_pipe.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(y_test, tfidf_combined_preds))\n",
    "metrics.confusion_matrix(y_test, tfidf_combined_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa3318f",
   "metadata": {},
   "source": [
    "The model is still struggling with low precision. This variant has significantly improved the recall of the previous TF-IDF models, while still maintained better precision than the summary-only model. However, there is still significant room for improvement on the precision. This model is still over-estimating the amount of fake reviews in the dataset, though using the word-embedding technique has vastly improved the performance over the original summary-only baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ab70e6",
   "metadata": {},
   "source": [
    "#### Next steps\n",
    "\n",
    "The TF-IDF uni-gram model appears to be a pretty good model for identifying fake reviews. It still has too many false negatives and therefore poor precision overall, but there has been notable improvements in performance over the original baseline model.\n",
    "\n",
    "* **Managing imbalanced classes** - One potential confounder could be the SMOTE oversampling that we are doing. In other applications, SMOTE has had a lot of success in rebalancing datasets and improving performance when datasets are heavily biased towards one class or another, but it is not the only way to rebalance datasets. We could potentially try other alternatives, such as random downsampling on the majority class, or we could utilize the built-in `class-weight` parameter on the `LinearSVC` model without resampling to instead indicate the bias of the training set and to weight the minority class more heavily.\n",
    "* **Feature engineering** - These models have only incorporated the simple summary statistics provided by Lu, as well as the TF-IDF embeddings. There are many other potential features that we have discussed that we should try to include in further iterations of the model, including the punctuation idea from above.\n",
    "* **Hyper-parameter tuning** - The LinearSVC model has several hyperparameters that we could use to improve the overall performance of the model. For the time being, I have only explored using the default parameters, but we could implement cross-validated grid searches to attempt to optimize the model. The primary hyperparameters we could use would be C, the L2 regularization parameter and the penalty, which by default is an L2 penalty but we could experiment with L1 for even sparser coefficient vectors.\n",
    "* **Alternative SVM classifier models** - the model I have been using is the LinearSVC class from sklearn, specifically because this class utilizes a different optimization algorithm from the standard SVC class that is _significantly_ more performant, but it limits the kernel to a linear kernel. Linear kernels have shown pretty good performance on text classification, but if we want to attempt other non-linear kernels, we will have to utilize the SGDClassifier class with an SVM optimization function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29153069",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gatech",
   "language": "python",
   "name": "gatech"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
